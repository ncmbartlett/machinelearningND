{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLND Capstone: Comparison of sentiment analysis using traditional machine learning methods and recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: executing \"Run All\" will take a very long time because it will train 54 RNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import get_file\n",
    "import time\n",
    "\n",
    "sns.set_style('dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this command if you do not have the 'punkt' nltk package installed\n",
    "\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
    "                                                      num_words=None,\n",
    "                                                      skip_top=0,\n",
    "                                                      maxlen=None,\n",
    "                                                      seed=113,\n",
    "                                                      start_char=1,\n",
    "                                                      oov_char=2,\n",
    "                                                      index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training set: 25000\n",
      "Length test set: 25000\n"
     ]
    }
   ],
   "source": [
    "print('Length training set:', len(X_train))\n",
    "print('Length test set:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict mappings from word --> id and from id --> word\n",
    "\n",
    "# All indices need to be shifted by 3. In the dictionary returned by imdb.get_word_index(), indexing starts at 1.\n",
    "# However, in the actual train/test data, the most frequent word ('the') is indexed as 4.\n",
    "\n",
    "index_from = 3  \n",
    "\n",
    "word2id = imdb.get_word_index()\n",
    "word2id = {key: value + index_from for key, value in word2id.items()}\n",
    "word2id[\"<PAD>\"] = 0\n",
    "word2id[\"<START>\"] = 1\n",
    "word2id[\"<UNK>\"] = 2\n",
    "\n",
    "id2word = {val: key for key, val in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 88584\n"
     ]
    }
   ],
   "source": [
    "print('Number of words in vocab:', len(word2id) - 3)  # -2 is to not take into account indices 0, 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retaining top 0.9543196910260109% of words\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of word counts\n",
    "\n",
    "all_counts = np.concatenate(X_train + X_test)\n",
    "print('Retaining top {}% of words'.format(len(np.where(all_counts < 12004)[0]) / len(all_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 12001th most frequent word appears in 0.098% (49) of the documents.\n"
     ]
    }
   ],
   "source": [
    "# Check frequency of 12001st word\n",
    "\n",
    "count = 0\n",
    "for rev in X_train:\n",
    "    if 12004 in rev:\n",
    "        count +=1\n",
    "for rev in X_test:\n",
    "    if 12004 in rev:\n",
    "        count +=1\n",
    "        \n",
    "print('The 12001th most frequent word appears in {}% ({}) of the documents.'.format((count / 50000) * 100, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training set: 25000\n",
      "Length test set: 25000\n"
     ]
    }
   ],
   "source": [
    "# Re-import data using only the top 12,000 words\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
    "                                                      num_words=12004,\n",
    "                                                      skip_top=0,\n",
    "                                                      maxlen=None,\n",
    "                                                      seed=113,\n",
    "                                                      start_char=1,\n",
    "                                                      oov_char=2,\n",
    "                                                      index_from=3)\n",
    "\n",
    "print('Length training set:', len(X_train))\n",
    "print('Length test set:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in training and test sets: 12000\n"
     ]
    }
   ],
   "source": [
    "# Check that there are 12000 unique words (minus indices 1 and 2)\n",
    "\n",
    "unique_words = set(np.concatenate(X_train + X_test))\n",
    "print('Number of unique words in training and test sets:', len(sorted(list(unique_words))) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 12000\n"
     ]
    }
   ],
   "source": [
    "# Remake the mappings taking into account the abridged vocabulary\n",
    "# This is necessary to avoid a needlessly large pre-trained embedding layer later\n",
    "\n",
    "index_from = 3  \n",
    "\n",
    "word2id = imdb.get_word_index()\n",
    "word2id = {key: value + index_from for key, value in word2id.items() if value <= 12000}\n",
    "word2id[\"<PAD>\"] = 0\n",
    "word2id[\"<START>\"] = 1\n",
    "word2id[\"<UNK>\"] = 2\n",
    "\n",
    "id2word = {val: key for key, val in word2id.items()}\n",
    "\n",
    "print('Number of words in vocab:', len(word2id) - 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of review lengths in the training and test sets combined.\n",
    "\n",
    "lengths = np.array([len(rev) for rev in np.concatenate([X_train, X_test])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 234.75892\n",
      "Std Dev: 172.91149458735703\n",
      "Min: 7\n",
      "Max: 2494\n"
     ]
    }
   ],
   "source": [
    "# Review length stats\n",
    "\n",
    "print('Mean:', lengths.mean())\n",
    "print('Std Dev:', lengths.std())\n",
    "print('Min:', lengths.min())\n",
    "print('Max:', lengths.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAKiCAYAAAAdYfAvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xt0VOW9//HPEJIQwkWUZIiKiFIDEiBJgUP1J5eANEBkIQRQTIRQuainAt4OlmK15SgoHklVOFg1QUBAKAWCQtVEoV7haBJiuJSC3GGChHDLlTC/P1gzzZBJMhOeXHm/1mIx8+zvfua7Z2YtP2yf2dtit9vtAgAAAHDVmtR1AwAAAEBjQbgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGNK0rhtAxS5duqTSUm6gCQAAUNd8fX08qiNc12OlpXbl5eXXdRsAAADXvKCglh7VsSwEAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADGla1w3g2pOU9BcdOLDfo9q8vNOSpOuua1Nj/dx6621KSJhUY/MDAIBrB+Eate7Agf3K3vNPlTa/vspan/xTkqRD50prpBef/NwamRcAAFybCNeoE6XNr1dB56FV1gXs/liSPKqtDsf8AAAAJrDmGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGEK4BAAAAQwjXAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcQ5K0ZUuatmxJq+s2YACfJQAAdadpXTeA+iEt7VNJUr9+UXXcCa4WnyUAAHWHM9cAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGEK4BAAAAQwjXAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDmtZ1AwDM2rnzR0nS6NH31XEnMKlduxs1adJUvfrqywoKClbTpk3VtKmPnnnm95Ls+tOfnteRI4c0btx4LV+eLH9/f82Z86pat26tV199SZJdzzzze7Vp06bC1zh9Olcvv/xHHTt2VDfeeJOee+4PldY79ik7v2TX66+/ohkz/qvKfcvO8frrr2jixMlavPgtWSwWPfPMrHL7O+oqm/vKGsfzhIQpevvtNyuc27SK+riyd0+Oqaq5r7Y3k3N708Mrr/x3rX0edansdzApaXGNv7em1NZ3obrqc38+L7zwwgt13QTcu3TJrsLCklp5rS++SJUkDRgwqFZey3Y2Xxfb/qLKWt+f90qSR7XV4fvzXllbN6+V464tq1evqOsWUAPOnz+n77/froKCfJ09e0Z5eaeVm3tKxcVF2rnzR6Wn/58kKSsrQ5JUWlqq3buzdfJkjrZv/9ZZGxnZq8LXWLYsSd9/v02lpReVl3e6ynrHPmXn37nzR23b9o1H+5adY9u2b7RzZ7YOHNhfYa+OusrmvrLG8Xz37srnNq2iPq58bU+Oqaq5r7Y3k3N708P27d/V2udRl8p+B/fv39dgjre2vgvVVRf9BQb6e1THshCgEeFsdeN24cL5cmOpqZ8oNfUTt/WHDx9y2ZaW9qlOnz7ttvb06VylpX1Wbu6K6h37fP75Zy71n3/+mex2uz7//LNK93WdI1V2u11HjhyqsNeydRXNfWXNgQP7nc8PH654btMq66Ns754cU1Vze3scle1/tXN700PZ71pNfx51qex7evjwoRp/b02pre9CddX3/lgWAklSXl6e8vJy9Yc/PFfjr3XgwH5ZLvnW+Ot4wlJSoAMH9tfKcQM14eLFi5VuLy0tdan9619X6pFHHi1Xt2bNSl286Pp/yiqr//c+F13qLRaLJOnSpUuV7lt2Drv9UrnxK1+7bF1Fc19Zk5j4mkdzm1ZZH2V79+SYqprb2+OobP+rndubHkpLXb83Nfl51CV33++afG9Nqa3vQnXV9/44cw0A1wi73a6tWz93u+0f//jC7XhF9Y597HZ7udeQLgemyvYtO4e7fyBc2WvZuormvrLmyJFDHs1tWmV9lO3dk2Oqam5vj6Oy/a92bm96KPu9qenPoy65+37X5HtrSm19F6qrvvfHmWtIkq677jpdd911evHFl2v8tf7wh+e04/DPNf46nrD7BujW9u1r5bhrA8tCUBmLxaK+fQe43XbPPf31ySebyo1XVO/Y59NPN7sEJYvFIrvdrqZNm1a6b9k50tI+LRdAruy1bF1Fc19Z067djTpx4liVc5tWWR9le/fkmKqa29vjqGz/q53bmx7Kfm9q+vOoS+6+3zX53ppSW9+F6qrv/XHmGgAasKZNm8rHx6fC7WW3NW3aVKNGPeC2Ljb2ATVt6rpcq7L6f+/T1KXe8bxJkyaV7lt2Doul/H+KrnztsnUVzX1lzbRpT3k0t2mV9VG2d0+Oqaq5vT2Oyva/2rm96cHHx/V7U5OfR11y9/2uyffWlNr6LlRXfe+PcA00IqtXp9R1C6hBgYEtyo0NHDhYAwcOdlvfvv0tLtuiou6t8JJVbdpcr6go16vmDBw4uNJLXLVpc73LlXYGDhysAQMGyWKxaMCAQR5dHuvyHANlsVh08823VNhr2bqK5r6y5tZbb3M+b9++4rlNq6yPsr17ckxVze3tcVS2/9XO7U0PZb9rNf151KWy72n79rfU+HtrSm19F6qrvvfHshAAaAAqus715TM2du3atbPcda6feOJptW7dWj/9tF+SvcqzO7GxD2jv3n86r3Pt6ZlU1/kvXxXBmzNJsbEP6PDhQy7Xua7ozHRVc19Z43he9jrXtXGWq6I+rnxtT46pqrmvtjeTc3vTw/79+2rt86hLZb+DSUmLG8zx1tZ3obrqc38W+5W/RkG9UVJSqry8/Fp5LcfVMmpzzXVB56FV1gbs/liSPKqtjoDdH6t7+7aNZs21VLufJQAA14qgoJYe1bEsBAAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGEK4BAAAAQwjXAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAkKZ13QDqh6ioe+u6BRjCZwkAQN0hXEOS1K9fVF23AEP4LAEAqDssCwEAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGEK4BAAAAQwjXAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhjSt6wZwbfLJz1XA7o89qDslSR7VVrcPqW2NzA0AAK49hGvUultvvc3j2rw8H0nSdde1qaFu2nrVDwAAQGUsdrvdXtdNwL2SklLl5eXXdRsAAADXvKCglh7VseYaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDLHa73V7XTQAAAACNAWeuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwpGldN4CKXbp0SaWl9rpuAwAA4Jrn6+vjUR3huh4rLbUrLy+/rtsAAAC45gUFtfSojmUhAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwJAGEa4XL16sJ554QgMHDlRoaKiioqI83vfVV19VaGioIiIi3G4vLi5WYmKioqKiFBYWpkGDBmnhwoUqKSlxW79u3TqNGDFC3bt311133aVZs2YpNzfXbW1mZqYmTJigiIgIRUZG6je/+Y127drlce8AAABoWCx2u91e101UJTQ0VNddd53uvPNOZWdnq0WLFkpLS6tyv127dik2NlZ+fn6SpPT09HI1jz32mFJTUzVq1ChFREQoPT1df/3rX3X//fdr7ty5LrXJycl6+eWX1bt3b8XExOjEiRNKTk7WjTfeqNWrV6t58+bO2oyMDMXHx8tqtSouLk6StGzZMp06dUorV65UaGholf2XlJQqLy+/yrr6rsgu5ZeUelTb3NdH/pYabggAAMBLQUEtPaprEOH68OHDat++vSQpJiZG+fn5VYbr0tJSjRkzRkFBQbpw4YJ+/PHHcuF6y5Ytmjx5shISEjRz5kzn+Ny5c5WUlKQVK1YoMjJSkpSbm6uoqCh16tRJq1atko+PjyQpLS1Njz76qGbMmKGpU6c654iNjdX+/fu1adMmWa1WSZLNZtOQIUMUHh6u9957r8rjbizh+nRxqT7fneNR7YDOwWrj51PDHQEAAHjH03DdIJaFOIK1N5YuXap9+/Zp9uzZFdakpKRIksaPH+8y7ni+YcMG51hqaqoKCgoUFxfnDNaSFBUVpfbt27vUHjx4UFlZWYqOjnYGa0myWq2Kjo7W119/rZMnT3p9TAAAAKjfGkS49tbRo0eVmJioxx9/XDfddFOFdVlZWbJarQoJCXEZDwkJUXBwsLKyslxqJbldu92jRw/t379fFy5cqLI2PDxcdrtd2dnZ3h8YAAAA6rVGGa5feOEF3XzzzUpISKi0Licnx+XMcllWq1U2m82l1jHurtZutztrHH8HBwe7rZXkMjcAAAAah6Z13YBpGzdu1D/+8Q998MEHatq08sMrLCx0/tjxSv7+/iosLHQ+LygokCS39f7+/s75qqp1jDlqAAAA0Hg0qjPXeXl5eumllxQbG+v8IWJlmjVrpuLiYrfbioqK1KxZM+fzgIAASXJbX1RU5JyvqlrHmKMGAAAAjUejOnP95ptvqqCgQGPGjNHBgwed44WFhbLb7Tp48KD8/Pyca6yDg4MrXJ5hs9lcloA4lnjYbDZ16NChXK3FYnHWOP52LA+5slZyv7wEAAAADVujOnN97Ngx5efna/To0Ro8eLDzz44dO1RQUKDBgwdr0qRJzvpu3brJZrPp+PHjLvMcP35cOTk5CgsLc6mV3F8rOzMzUx07dlRgYGCVtRkZGbJYLOratevVHzAAAADqlUYVridNmqTExMRyfzp16iR/f38lJibqueeec9bHxMRIkpYsWeIyj+P5fffd5xwbOHCgmjVrpuXLl6u09N83RElLS9Phw4ddajt06KCwsDBt3rzZ5cy4zWbT5s2b1adPHwUFBZk9eAAAANS5BrEsZN26dTp27JikyzdzKSkp0cKFCyVJN954o0aMGCHJ/aXvJGn58uU6duyYoqOjXcb79++vAQMGKCkpSefOnVN4eLgyMjK0Zs0aDR8+XD179nTWXn/99Zo2bZrmzZunCRMmKCYmRjabTUlJSbrtttvKXSt71qxZevjhh/XQQw+53KHRbre73LAGAAAAjUeDuENjfHy8tm3b5nZb7969tXTp0ir3d3eHRunyjxEXLlyolJQU56X5Ro4cqcmTJ8vX17dc/dq1a5WcnKyffvpJLVq0UP/+/fX000/rhhtuKFebnp6uBQsWaMeOHZKkyMhIPfnkkx4vCeEOjQAAAPVDo7r9+bWKcA0AAFA/NKrbnwMAAAANAeEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGEK4BAAAAQwjXAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGNK3rBjyxePFiZWdnKzs7W0eOHNFNN92ktLS0cnVFRUVav369Pv/8c+3Zs0c///yzgoKC1KNHDz3++OO6/fbby+1TXFysRYsWaf369crJyVG7du00cuRITZo0Sb6+vuXq161bp+TkZO3fv18tWrTQgAED9NRTT+n6668vV5uZmanXX39dmZmZslgsioiI0NNPP60uXbqYeWMAAABQr1jsdru9rpuoSmhoqK677jrdeeedys7OVosWLdyG63379mno0KH65S9/qbvvvlvBwcE6cuSIVqxYofz8fL3zzjvq06ePyz6PPfaYUlNTNWrUKEVERCg9PV1//etfdf/992vu3LkutcnJyXr55ZfVu3dvxcTE6MSJE0pOTtaNN96o1atXq3nz5s7ajIwMxcfHy2q1Ki4uTpK0bNkynTp1SitXrlRoaGiVx11SUqq8vPzqvGX1yuniUn2+O8ej2gGdg9XGz6eGOwIAAPBOUFBLj+oaRLg+fPiw2rdvL0mKiYlRfn6+23B9+vRpnThxotyZ4X/9618aMWKE7rjjDq1du9Y5vmXLFk2ePFkJCQmaOXOmc3zu3LlKSkrSihUrFBkZKUnKzc1VVFSUOnXqpFWrVsnH53IATEtL06OPPqoZM2Zo6tSpzjliY2O1f/9+bdq0SVarVZJks9k0ZMgQhYeH67333qvyuAnXAAAA9YOn4bpBrLl2BOuqtGnTxu2Si06dOumOO+7Q3r17XcZTUlIkSePHj3cZdzzfsGGDcyw1NVUFBQWKi4tzBmtJioqKUvv27V1qDx48qKysLEVHRzuDtSRZrVZFR0fr66+/1smTJz06JgAAADQcDSJcX61Lly4pJydHbdu2dRnPysqS1WpVSEiIy3hISIiCg4OVlZXlUitJERER5ebv0aOH9u/frwsXLlRZGx4eLrvdruzs7Ks7KAAAANQ710S4XrFihU6ePKkRI0a4jOfk5LicWS7LarXKZrO51DrG3dXa7XZnjePv4OBgt7WSXOYGAABA49Dow/UPP/yguXPnqnPnzi5roiWpsLBQfn5+bvfz9/dXYWGh83lBQYEkua339/d3zldVrWPMUQMAAIDGo1GH6x9//FFTpkxRcHCw3n77bWcIdmjWrJmKi4vd7ltUVKRmzZo5nwcEBEiS2/qioiLnfFXVOsYcNQAAAGg8Gm24zs7O1sSJE9WyZUu9//77bpdzBAcHV7g8w2azuezjWOLhrt5ms8lisThrHH87lodcWSu5X14CAACAhq1Rhuvs7GwlJCQoMDBQS5Ys0U033eS2rlu3brLZbDp+/LjL+PHjx5WTk6OwsDCXWklKT08vN09mZqY6duyowMDAKmszMjJksVjUtWvX6h0cAAAA6q1GF6537typiRMnqnnz5nr//fcrvYxfTEyMJGnJkiUu447n9913n3Ns4MCBatasmZYvX67S0lLneFpamg4fPuxS26FDB4WFhWnz5s0uZ7ptNps2b96sPn36KCgo6OoOFAAAAPVOg7j9+bp163Ts2DFJl2/mUlJSooULF0qSbrzxRudVQI4ePaqEhASdOXNG8fHx+uGHH/TDDz+4zHXvvfc676TYv39/DRgwQElJSTp37pzCw8OVkZGhNWvWaPjw4erZs6dzv+uvv17Tpk3TvHnzNGHCBMXExMhmsykpKUm33XZbuWtlz5o1Sw8//LAeeughlzs02u12lxvWAAAAoPFoEHdojI+P17Zt29xu6927t5YuXSpJ+u677/Twww9XOldqaqpuvvlm5/OioiItXLhQKSkpzkvzjRw5UpMnT5avr2+5/deuXavk5GT99NNPatGihfr376+nn35aN9xwQ7na9PR0LViwQDt27JAkRUZG6sknn/R4SQh3aAQAAKgfGtXtz69VhGsAAID6oVHd/hwAAABoCAjXAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGEK4BAAAAQwjXAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwpEGE68WLF+uJJ57QwIEDFRoaqqioqErrMzMzNWHCBEVERCgyMlK/+c1vtGvXLre1NptNzz77rPr06aPu3btr5MiR2rRpk9va4uJiJSYmKioqSmFhYRo0aJAWLlyokpISt/Xr1q3TiBEj1L17d911112aNWuWcnNzvTt4AAAANBhN67oBT/zP//yPrrvuOt155506d+5cpbUZGRmKj4+X1WrVtGnTJEnLli3TuHHjtHLlSoWGhjpr8/LyNG7cOOXm5mrChAlq166dNm7cqOnTpys/P1+jRo1ymXv69OlKTU3VqFGjFBERofT0dCUmJurQoUOaO3euS21ycrJefvll9e7dW7NmzdKJEyeUnJysjIwMrV69Ws2bNzf07gAAAKC+sNjtdntdN1GVw4cPq3379pKkmJgY5efnKy0tzW1tbGys9u/fr02bNslqtUq6fHZ6yJAhCg8P13vvveesfeWVV/Tuu+9q0aJFzrPhpaWlGjt2rA4fPqy0tDQFBgZKkrZs2aLJkycrISFBM2fOdM4xd+5cJSUlacWKFYqMjJQk5ebmKioqSp06ddKqVavk4+MjSUpLS9Ojjz6qGTNmaOrUqVUed0lJqfLy8r19u+qd08Wl+nx3jke1AzoHq42fTw13BAAA4J2goJYe1TWIZSGOYF2VgwcPKisrS9HR0c5gLUlWq1XR0dH6+uuvdfLkSef4xo0bdcstt7gsM/Hx8VFcXJzy8vK0ZcsW53hKSookafz48S6v6Xi+YcMG51hqaqoKCgoUFxfnDNaSFBUVpfbt27vUAgAAoPFoEOHaU1lZWZKkiIiIctvCw8Nlt9uVnZ0tScrJyZHNZlOPHj3c1padz/HYarUqJCTEpTYkJETBwcHlaivqo0ePHtq/f78uXLjg7eEBAACgnmtU4Ton5/LSg+Dg4HLbyi4RKVtb9gz3lbWOGsdjd7WOese8nsxtt9td5gYAAEDj0KjCdUFBgSTJz8+v3DbHmKOmsLCwwlp/f3+XWke9u1pHvWO+qvpwzF22HgAAAI1DowrXAQEBki5fMu9KjjFHTbNmzSqsLSoqcql11LurddQ75quqD8fcZesBAADQODSqcO1YDuJuyYVj2YZjqYajtuxyjitryy4vCQ4OdlvrqC+7BKSquS0Wi9ulKwAAAGjYGlW47tatmyQpPT293LaMjAxZLBZ17dpV0uUAbLValZmZ6ba27HyOxzabTcePH3epPX78uHJychQWFuZRH5mZmerYsaPzEn8AAABoPBpVuO7QoYPCwsK0efNml7PGNptNmzdvVp8+fRQUFOQcHzZsmA4dOuRyzezS0lItW7ZMrVq1Ut++fZ3jMTExkqQlS5a4vKbj+X333eccGzhwoJo1a6bly5ertLTUOZ6WlqbDhw+71AIAAKDx8HnhhRdeqOsmqrJu3TqlpaVp+/bt+u6771RQUKCLFy9q+/btOnr0qDp37uys/cUvfqE1a9bok08+0aVLl5SRkaEXXnhB+fn5WrBggdq2beus7dq1qzZt2qT169eruLhYBw4c0CuvvKL09HTNnj3b5VJ6t956q7Kzs/W3v/1NJ06cUG5urj744AN98MEHGj58uCZMmOCsDQgIkL+/v9auXavt27erpKREaWlpmjdvntq3b6+XXnqpwh9HlnXpkl2Fhe5vrd6QFJbadeBnzy492LFtoAJ8GtW/+QAAQCMQGOjvUV2DuENjfHy8tm3b5nZb7969tXTpUpex9PR0LViwQDt27JAkRUZG6sknn3QuCSnLZrNp/vz52rp1q/Lz89WpUydNmjRJQ4cOLVdbVFSkhQsXKiUlxXlpvpEjR2ry5Mny9fUtV7927VolJyfrp59+UosWLdS/f389/fTTuuGGGzw6bu7QCAAAUD94eofGBhGur1WEawAAgPqhUd3+HAAAAGgICNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGEK4BAAAAQwjXAAAAgCGEawAAAMAQwjUAAABgCOEaAAAAMIRwDQAAABhCuAYAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhXofrixcv1kQfAAAAQIPX1Nsd+vfvr1GjRik2Nlbt27eviZ5wDbNYLDpdXOpRbXNfH/lbarghAAAAL1jsdrsyUSTyAAAgAElEQVTdmx169+6ts2fPqkmTJrrrrrv0wAMPKCoqSk2asMLEtJKSUuXl5dd1G1ftdHGpPt+d41Htr34RpG/2nvSodkDnYLXx87ma1gAAADwSFNTSozqvz1x/+eWX+vjjj7Vq1Sp9+eWX+uqrrxQUFKTY2FiNHj1aISEhXjcLAAAANAZen7ku61//+pdWrlyplJQUnTlzRj4+Prrnnnv0wAMPqF+/frJY+H/2V4Mz15XjzDUAAKgtnp65vqpw7VBcXKyPP/5YH374oX744QdZLBa1a9dOo0eP1pgxY9S2bdurfYlrEuG6coRrAABQWzwN10YWSvv5+WnQoEEaNmyYrFar7Ha7jh8/rj//+c+KiorSvHnzVFxcbOKlAAAAgHrL6zXXV8rKytKqVav00UcfqbCwUM2bN9e4ceM0atQo7dy5U8nJyUpOTlZRUZGef/55Ez0DAAAA9VK1loXk5+crJSVFq1at0q5du2S32xUaGqoHH3xQw4cPV/PmzZ21paWlmjhxovbs2aNvv/3WaPONHctCKseyEAAAUFtq7Gohzz//vD766CPl5+eradOmGjZsmMaNG6fIyEi39T4+PurTp4+2bdvm7UsBAAAADYrX4frDDz/UTTfdpClTpig2NlbXX399lfv06tVLU6ZMqVaDAAAAQEPhdbhevHix+vbt69Vl9nr27KmePXt6+1IAAABAg+J1uO7Xr19N9AEAAAA0eF5fiu/bb7/V7NmzlZPj/gdqNptNs2fP1vbt26+6OQAAAKAh8frM9dKlS/Wvf/1LwcHBbrdbrVZt375dZ86cUa9eva66QQAAAKCh8PrMdXZ2doVXBnH45S9/qaysrGo3BQAAADREXofrU6dOVXjW2qFt27Y6depUtZsCAAAAGiKvw3XLli1ls9kqrbHZbAoICKh2UwAAAEBD5HW47tatmz777DP9/PPPbrefPHlSn332mbp163bVzQEAAAANidfh+qGHHtL58+f10EMPacuWLbp48aIk6eLFi/riiy8UFxenCxcuKD4+3nizAAAAQH3m9dVC+vbtqylTpmjx4sWaOnWqmjRpojZt2uj06dO6dOmS7Ha7pkyZwvWwAQAAcM3xOlxL0owZMxQZGamlS5dqx44dOnXqlFq2bKkePXooLi6OYA0AAIBrUrXCtXT5To2EaAAAAODfvF5zDQAAAMC9ap+5lqTi4mKdPXtWpaWlbrdbrdarmR4AAABoUKoVrjdu3Ki//OUv2rt3r+x2u9sai8WinTt3XlVzAAAAQEPidbhet26dZs6cqSZNmqhHjx4KCQmRj49PTfQGAAAANCheh+t3331XLVu21PLly3XHHXfURE9X7cKFC1q6dKk++ugjHTlyRH5+furYsaPGjBmj+++/XxaLxVmbmZmp119/XZmZmbJYLIqIiNDTTz+tLl26lJvXZrPptdde09atW5Wfn69OnTpp0qRJGjJkSLna4uJiLVq0SOvXr1dOTo7atWunkSNHatKkSfL19a3R4wcAAEDd8DpcHzhwQPfff3+9DdaXLl3SpEmTlJ6erhEjRiguLk4FBQX66KOP9Nxzz2nfvn165plnJEkZGRmKj4+X1WrVtGnTJEnLli3TuHHjtHLlSoWGhjrnzcvL07hx45Sbm6sJEyaoXbt22rhxo6ZPn678/HyNGjXKpY/p06crNTVVo0aNUkREhNLT05WYmKhDhw5p7ty5tfeGAAAAoNZ4Ha5bt24tf3//mujFiMzMTH3//fcaP368fve73znHx40bpyFDhmjVqlXOcD1nzhz5+vpq+fLlzh9fDhkyREOGDNG8efP03nvvOfd/++23deTIES1atEhRUVGSpNjYWI0dO1avvPKKoqOjFRgYKEnasmWLUlNTlZCQoJkzZ0qSRo8erVatWikpKUljxoxRZGRkrbwfAAAAqD1eX4qvX79+2rZtW4U/ZKxr58+flyQFBwe7jPv5+alNmzYKCAiQJB08eFBZWVmKjo52uaqJ1WpVdHS0vv76a508edI5vnHjRt1yyy3OYC1JPj4+iouLU15enrZs2eIcT0lJkSSNHz/epQfH8w0bNpg4VAAAANQzXofrp556SgUFBXrxxRdVUFBQEz1dle7du6tVq1Z65513tGnTJh07dkz79u3Ta6+9puzsbP32t7+VJGVlZUmSIiIiys0RHh4uu92u7OxsSVJOTo5sNpt69OjhtrbsfI7HVqtVISEhLrUhISEKDg52qQUAAEDj4fWykKefflotWrTQqlWrlJKSoo4dO6pVq1bl6iwWi959910jTXqjdevWWrRokWbNmqXp06c7xwMDA/XGG29o0KBBki4HZqn8GW7p39fnttlsLrXurtvtGHPUOB536tTJbX9Wq1UnTpzw+rgAAABQ/3kdrr/++mvn4wsXLujHH390W1f2ihy1rXnz5rrjjjsUFRWlyMhI5eXl6YMPPtBTTz2lhQsX6u6773aedffz8yu3v2PMUVNYWFhhrWP9edmz+IWFhW5rHfWO+QAAANC4eB2uHUsl6qs9e/bogQce0HPPPacHH3zQOR4TE6OYmBjNnj1bn376qXPtdXFxcbk5HGOOmmbNmlVYW1RU5FLrqHdX66h3zAcAAIDGxes11z4+Ph7/qQvJyckqKipSdHS0y3hAQID69++vo0eP6ujRo87lIGWXczg4loM4lnw4ah3j7mrLLi8JDg52W+uo57bwAAAAjZPX4bq+c4TlS5culdt28eJF59/dunWTJKWnp5ery8jIkMViUdeuXSVdDstWq1WZmZluayU553M8ttlsOn78uEvt8ePHlZOTo7CwsOocGgAAAOq5aoVru92uDz74QA8++KD+4z/+wyVY7tq1S3PmzNGBAwdM9eiV22+/XZK0du1al/GzZ88qNTVVrVu3VocOHdShQweFhYVp8+bNLmeZbTabNm/erD59+igoKMg5PmzYMB06dEhpaWnOsdLSUi1btkytWrVS3759neMxMTGSpCVLlrj04Hh+3333GTpaAAAA1Cder7kuKSnRlClT9M0336hly5by8/NznhGWpBtvvFGrVq1S69atnZe9q03jx4/X+vXr9dprr+mf//ynIiMjdebMGX344Yc6efKknn/+eeeSlVmzZunhhx/WQw89pLi4OEmX79Bot9udN39xmDx5sv7+97/rqaeeUkJCgqxWqzZu3KisrCzNmTNHLVq0cNb2799fAwYMUFJSks6dO6fw8HBlZGRozZo1Gj58uHr27Fl7bwgAAABqjcXu5d1gFi9erNdff12PPfaYHn/8cS1cuFALFy7Url27nDUJCQnKz8/XqlWrjDfsiUOHDumtt97SN998o1OnTsnf319dunTR+PHjNXjwYJfa9PR0LViwQDt27JAkRUZG6sknn3QuCSnLZrNp/vz52rp1q/Lz89WpUydNmjRJQ4cOLVdbVFSkhQsXKiUlRTk5ObJarRo5cqQmT54sX19fj46jpKRUeXn51XgH6pfTxaX6fHf5te3u/OoXQfpm78mqCyUN6BysNn51s7YfAABcW4KCWnpU53W4HjZsmFq2bKmVK1dKkt5880299dZbLuH6+eefV1pamr788ktvpsYVCNeVI1wDAIDa4mm49nrN9eHDh93e1bCs1q1bKy8vz9upAQAAgAbN63Dt7++v8+fPV1pz7Ngxt3dtBAAAABozr8N1586d9dVXX1V4k5Tz58/rq6++Uvfu3a+6OQAAAKAh8Tpcjx49WseOHdPMmTN14cIFl23nz5/X7373O505c0Zjx4411iQAAADQEHh9Kb7hw4frq6++0vr16/XZZ585l3+MGTNG//znP1VYWKixY8dqwIABxpsFAAAA6jOvw7UkzZs3Tz179tT777+vvXv3SpJ27Nihjh07KiEhQWPGjDHaJAAAANAQVCtcS5eXh4wePVoXLlzQmTNn1LJlS7Vs6dklSgAAAIDGqNrh2iEwMFCBgYEmegEAAAAaNK9/0AgAAADAPa/PXP/617/2uPbvf/+7t9MDAAAADZbX4bqgoEAWi6Xc+Llz55Sff/lW3W3btpWPD7elBgAAwLXF63C9devWCrft27dPL730kkpKSvTOO+9cVWMAAABAQ2N0zfXtt9+uN998U0ePHtVbb71lcmoAAACg3jP+g8aAgAD9v//3/5SSkmJ6agAAAKBeq5Grhfj6+urkyZM1MTUAAABQbxkP13l5efr000/Vrl0701MDAAAA9ZrXP2j83//9X7fjFy9e1IkTJ/Tpp5/q7Nmzmj59+lU3BwAAADQkXofrBQsWVLq9efPmmjx5sqZMmVLtpgAAAICGyOtwnZSU5HbcYrGodevWuv322+Xn53fVjQEAAAANjdfh+le/+lVN9AEAAAA0eDVytRAAAADgWuT1mWubzVbtF7NardXeFwAAAKjvvA7X/fr1k8Vi8fqFLBaLdu7c6fV+AAAAQEPhdbiOiYnR8ePH9f333yswMFChoaFq27atfv75Z+3Zs0cXLlxQz549FRISUhP9AgAAAPWW1+H6P//zPzV27FjFxcXpiSeeUKtWrZzbzp49q8TERG3cuFH//d//rQ4dOhhtFgAAAKjPvP5B4/z583X77bfr97//vUuwlqRWrVpp9uzZuu222zR//nxjTQIAAAANgdfhevv27erVq1elNb169dK2bduq3RQAAADQEHkdrouLi/Xzzz9XWnPy5EkVFxdXuykAAACgIfI6XIeGhurjjz/W7t273W7ftWuXNm3apC5dulx1cwAAAEBD4vUPGh9//HFNmTJFo0eP1ogRI9SzZ0/n1UK2b9+u9evXq7S0VI8//nhN9AsAAADUWxa73W73dqePP/5Yf/jDH3Tu3DmXa17b7Xa1bNlSL774ooYOHWq00WtRSUmp8vLy67qNq3a6uFSf787xqPZXvwjSN3tPelQ7oHOw2vj5XE1rAAAAHgkKaulRnddnriVp6NCh6tu3rz777DNlZ2fr/PnzatGihbp27apBgwapRYsW1ZkWAAAAaNCqFa4lqUWLFhoxYoRGjBhhsh8AAACgwfL6B41XOn/+vHJyPPtf/gAAAEBjVq1wXVBQoFdffVV9+/ZVr1691L9/f+e2HTt2aOrUqdq1a5epHgEAAIAGwetwff78eT3wwAN699131bp1a3Xs2FFlfxPZqVMnfffdd0pJSTHaKAAAAFDfeR2uFy1apD179mjOnDlKSUnRkCFDXLY3b95cvXr10rfffmusSQAAAKAh8Dpcf/LJJ7r77rsVGxsrSS6X4nO46aabdOLEiavvDgAAAGhAvA7XJ06cUOfOnSutad68uc6dO1ftpgAAAICGyOtw3bx5c+Xm5lZac+TIEbVp06baTQEAAAANkdfhulu3bvriiy904cIFt9tPnjyprVu3KiIi4qqbAwAAABoSr8N1fHy8Tp8+ralTp+rAgQMu2w4cOKAZM2aoqKhI8fHxpnoEAAAAGgSv79DYr18/Pfroo1q0aJGGDBkiPz8/SdLdd9+t3Nxc2e12zZgxQz179jTeLAAAAFCfVev259OmTVPPnj21dOlSZWRkqLi4WMXFxbr77ruVkJCgu+++23SfAAAAQL1XrXAtXT5TTYgGAAAA/s3rNdcTJ07UG2+8URO9GJWXl6d58+bp3nvvVbdu3dSnTx/Fx8fr//7v/1zqMjMzNWHCBEVERCgyMlK/+c1vKrx1u81m07PPPqs+ffqoe/fuGjlypDZt2uS2tri4WImJiYqKilJYWJgGDRqkhQsXqqSkxPixAgAAoH7w+sz1999/r7CwsJroxZijR48qPj5e+fn5io2N1a233qrz589rz549stlszrqMjAzFx8fLarVq2rRpkqRly5Zp3LhxWrlypUJDQ521eXl5GjdunHJzczVhwgS1a9dOGzdu1PTp05Wfn69Ro0a59DB9+nSlpqZq1KhRioiIUHp6uhITE3Xo0CHNnTu3dt4IAAAA1Cqvw/Utt9yi48eP10QvxjzzzDMqLS3Vhg0bFBwcXGHdnDlz5Ovrq+XLl8tqtUqShgwZoiFDhmjevHl67733nLVvv/22jhw5okWLFikqKkqSFBsbq7Fjx+qVV15RdHS0AgMDJUlbtmxRamqqEhISNHPmTEnS6NGj1apVKyUlJWnMmDGKjIysqcMHAABAHfF6WUhsbKy2bt1ab29vvn37dn3//fd65JFHFBwcrJKSEhUUFJSrO3jwoLKyshQdHe0M1pJktVoVHR2tr7/+WidPnnSOb9y4UbfccoszWEuSj4+P4uLilJeXpy1btjjHU1JSJEnjx493eU3H8w0bNpg5WAAAANQrXofrX//614qIiNCDDz6oFStW6Mcff5TNZnP7py44Qm5ISIimTp2qHj16KDw8XL/+9a+1fv16Z11WVpYkub3ZTXh4uOx2u7KzsyVJOTk5stls6tGjh9vasvM5HlutVoWEhLjUhoSEKDg42KUWAAAAjYfXy0L69+8vi8Uiu92uP/7xjxXWWSwW7dy586qaq46ffvpJkjR79mx16NBBc+fOVUlJiZKSkvTss8/q4sWLGjVqlHJyciTJ7bIRx5lsxz8QHLVlz3BfWeuocTzu1KmT2/6sVmu9PesPAACAq+N1uI6JiZHFYqmJXoxw3JY9MDBQ77//vvMmN4MGDdKgQYP0+uuv6/7773cuFXFsL8sx5qgpLCyssNbf39+l1lHvrtZR75gPAAAAjYvX4Xr+/Pk10YcxzZo1kyQNGzbMJeC2bt1aUVFRWrdunX766ScFBARIunzJvCs5xhw1jjnd1RYVFbnUOurd1TrqHfMBAACgcfF6zXV951imERQUVG6bY+zMmTPO5SBll3M4OJaDOOZy1LpbR+4YK7u8JDg4uMI15zabze3yEgAAADR8HoXrdevWaffu3TXdixHdu3eXJLfrmh1jN9xwg7p16yZJSk9PL1eXkZEhi8Wirl27Sroclq1WqzIzM93WSnLO53hss9nKXbLw+PHjysnJqffXCQcAAED1eBSuZ86cqc8++8xl7G9/+5sefvjhGmnqagwaNEiBgYHasGGDc/21dPkMdWpqqm699VZ16NBBHTp0UFhYmDZv3uxyltlms2nz5s3q06ePy9nvYcOG6dChQ0pLS3OOlZaWatmyZWrVqpX69u3rHI+JiZEkLVmyxKU3x/P77rvP7EEDAACgXvB6zbXD0aNHtX37dpO9GNG6dWv913/9l55//nmNHTtWo0aNUklJiVasWKGSkhLNnj3bWTtr1iw9/PDDeuihhxQXFyfp8h0a7Xa78+YvDpMnT9bf//53PfXUU0pISJDVatXGjRuVlZWlOXPmqEWLFs7a/v37a8CAAUpKStK5c+cUHh6ujIwMrVmzRsOHD1fPnj1r580AAABArap2uK7Pxo4dqzZt2uidd95RYmKiLBaLIiIiNH/+fP3yl7901kVGRmrp0qVasGCBEhMTnWOJiYnq3Lmzy5xt2rTRihUrNH/+fC1fvlz5+fnq1KmTXn/9dQ0dOrRcD4mJiVq4cKFSUlK0fv16Wa1WPfHEE5o8eXLNHjwAAADqTKMM15I0ePBgDR48uMq6iIiIcss3KmK1WvXqq696VOvv768ZM2ZoxowZHtUDAACg4Wt0VwsBAAAA6orH4bo+3zgGAAAAqA88Xhby5ptv6s033yw33qVLF7f1dXX7cwAAAKCueByu7Xa7VxN7Ww8AAAA0dB6F64ZyAxkAAACgLvGDRgAAAMCQRnspPjR+FotFp4tLPa5v7usjf36XCwAAahDhGg1WwcVL+mbvSY/rB3QOlr+fTw12BAAArnUsCwEAAAAMIVwDAAAAhhCuAQAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGNK0rhtAw1Rkl/JLSj2qLbXXcDMAAAD1BOEa1ZJfUqrPd+d4VPurXwTVcDcAAAD1A8tCAAAAAEMI1wAAAIAhhGsAAADAEMI1AAAAYAjhGgAAADCEcA0AAAAYQrgGAAAADCFcAwAAAIYQrgEAAABDCNcAAACAIYRrAAAAwBDCNQAAAGAI4RoAAAAwhHANAAAAGEK4BgAAAAwhXAMAAACGEK4BAAAAQwjXAAAAgCGEawAAAMCQayJcFxQUaODAgQoNDdUf//jHctv379+vxx57TL169VJ4eLjGjRunb775xu1c586d05/+9Cfdc8896tatm4YNG6YPPvhAdru9XO2lS5eUnJys6OhodevWTf369dPcuXOVn59v/BgBAABQ95rWdQO14c9//rNyc3Pdbjt06JAefPBB+fj46JFHHlGLFi20evVqPfLII/rLX/6iu+66y1lbXFyshIQE7dq1S3Fxcbr99tu1detWvfjiizp16pR++9vfusz90ksvaenSpbr33ns1ceJE7du3T0uXLtXOnTuVnJysJk2uiX/bAAAAXDMafbjOzs7WkiVL9Mwzz2ju3Lnltr/22ms6e/as1q5dqy5dukiSRowYoZiYGL344ovavHmzLBaLJGn16tXKysrS73//e8XHx0uSxowZo9/+9rdavHixRo4cqZtuukmStHfvXi1btkyDBw/WG2+84Xy9m2++WXPmzNFHH32k++67r6YPHwAAALWoUZ86LS0t1ezZs3XPPffo3nvvLbc9Pz9faWlp6t27tzNYS1JgYKBiY2N14MABZWVlOcc3btyogIAAjRkzxmWe8ePHq6SkRB9//LFLrd1u1/jx411qx4wZo4CAAG3YsMHUYQIAAKCeaNThOjk5Wfv379fs2bPdbt+zZ4+Ki4sVHh5ebptjzBGuL126pJ07d6pLly7y9/d3qe3evbssFotLEP/xxx/VpEkTde/e3aXW399fnTt3dqkFAABA49Bow/Xhw4f1xhtv6LHHHtPNN9/stiYnJ0eSZLVay21zjNlsNknSmTNnVFhY6LbWz89Pbdq0cc7nmLtNmzby8/NzO/fp06dVXFzs/YEBAACg3mq04fqFF15Q+/btlZCQUGFNQUGBJLkNwI6z046awsLCCmsd9Y5ax36V1ZadEwAAAI1Do/xB4/r16/XVV19p2bJl8vX1rbAuICBAktyeQS4qKnKpadasWYW1jnpHrWO/U6dOVVhbdk4AAAA0Do3uzHVxcbHmzp2rfv36KSgoSAcPHtTBgwd17NgxSZevU33w4EGdPXtWwcHBkv699KMsx5hjGUjr1q3VrFkzt7XFxcU6ffq0cz5JCg4OrnDph81mq3DJCAAAABquRnfmurCwULm5ufriiy/0xRdflNu+YcMGbdiwQc8++6weeOAB+fn5KSMjo1ydYywsLEyS1KRJE915553atWuXiouLXYLxjh07ZLfbnbWO/b788kvt2LFDPXv2dI4XFRVp9+7dLmMAAABoHBpduA4ICFBiYmK58dzcXL344ou65557FBsbq9DQUAUGBmrAgAH69NNPtXv3bnXu3FmSdOHCBa1Zs0a33nqry9U+YmJi9MMPP2jVqlXO61xL0pIlS9S0aVMNHTrUOTZ06FAtXrxYS5YscQnSH374oQoKCrjGNQAAQCPU6MK1r6+voqOjy40fOXJEknTLLbe4bH/qqaf07bffauLEiZowYYICAwO1evVq2Ww2LV78/9u776gorr9/4O+lCmLBiFixoLuAWEAFMcWuaDD2jlEMavSIseVRU36xmxi/EQORR5MYKaLYCypfDXZFIBEFRdDYUBQwCCpSFtj5/eHZeRx3QdBBFN+vc3Iidz57587eLZ+9c+fOOvEGMgAwfPhw7NixA99//z1SU1Nha2uL48eP4/Dhw5g6dapkVRKVSoWxY8ciJCQE06dPR9euXcU7NLq4uDC5JiIiIqqCqlxyXV5NmzbF5s2bsWrVKqxfvx6FhYVwcHDAb7/9Jrn1OfB0pZCNGzfC19cX4eHhyM7Oho2NDb799luMHTtWp+6vvvoKjRo1QlhYGI4dOwZLS0t4enpixowZvPU5ERERURWkEARBqOxGkH6FhcXIzs6t7GbolaUuxtGkjBcHAnBrZYWoq/crNRYAutvVg6WJYZnjiYiIiLSsrGqUKY7Dp0REREREMmFyTUREREQkEybXREREREQyeecvaKR3h0KhQJa6uEyx5saGMFW8OI6IiIjoWUyu6Z2RV6Qp8wWQ3e3qwZQXPxIREVE5cVoIEREREZFMmFwTEREREcmEyTURERERkUyYXBMRERERyYTJNRERERGRTJhcExERERHJhMk1EREREZFMmFwTEREREcmEyTURERERkUyYXBMRERERyYTJNRERERGRTJhcExERERHJhMk1EREREZFMmFwTEREREcmEyTURERERkUyYXBMRERERyYTJNRERERGRTJhcExERERHJhMk1EREREZFMmFwTEREREcmEyTURERERkUyYXBMRERERyYTJNRERERGRTJhcExERERHJhMk1EREREZFMjCq7AURvIoVCgSx1cZlizY0NYaqo4AYRERHRW4HJNZEeeUUaRF29X6bY7nb1YGpiWMEtIiIiorcBp4UQEREREcmEyTURERERkUyYXBMRERERyYTJNRERERGRTJhcExERERHJhMk1EREREZFMmFwTEREREcmEyTURERERkUyYXBMRERERyYTJNRERERGRTJhcExERERHJhMk1EREREZFMmFwTEREREcnEqLIbILcbN25g7969OH36NFJSUlBQUAAbGxu4u7tj/PjxMDc3l8Rfv34dq1atQmxsLAoLC+Hg4AAfHx+4ubnp1P348WP4+vri0KFDyM7Oho2NDcaOHYvRo0dDoVBIYjUaDYKCgrBlyxakpqaiTp066NevH2bMmKHTBiIiIiKqGqpccr1jxw5s2rQJPXr0wIABA2BkZITo6Gj4+vri4MGD2Lp1K6pVq8FsTAIAACAASURBVAYASElJwejRo2FoaAhvb29YWFhg27Zt8Pb2xq+//oouXbqI9arVanh5eeHy5cvw9PSEra0tTpw4gUWLFiEzMxM+Pj6SdixfvhzBwcHo3bs3Jk6ciGvXriE4OBiJiYnYuHEjDAx40oCIiIioqqlyyXXfvn0xZcoU1KhRQywbPXo0mjZtiv/93//F9u3b4enpCQD4z3/+g0ePHmHnzp2wt7cHAAwaNAgeHh5YtGgRIiIixBHpbdu2ISEhAd988w3GjRsHABgxYgR8fHywbt06DBkyBI0aNQIAXL16FSEhIejTpw/8/PzEdjRu3BhLly7F/v37MWDAgNfyfBARERHR61Plhk/btGkjSay1+vfvDwC4cuUKACA3NxdHjhyBi4uLmFgDQPXq1TFs2DDcvHkTCQkJYnl4eDjMzMwwYsQISb3jx49HYWEhDhw4IIkVBAHjx4+XxI4YMQJmZmbYu3fvqx8oEREREb1xqlxyXZK0tDQAQN26dQEAycnJUKvVaN++vU6stkybXGs0GiQmJsLe3h6mpqaS2LZt20KhUEgS8YsXL8LAwABt27aVxJqamsLOzk4SS0RERERVxzuRXBcXFyMgIABGRkbw8PAAAGRkZAAArK2tdeK1Zenp6QCAhw8fIj8/X2+siYkJLC0txfq0dVtaWsLExERv3VlZWVCr1a9+YERERET0Rqlyc671Wb58OeLi4jB79my0aNECAJCXlwcAehNg7ei0NiY/P7/EWG28Nlb7uNJitXWWFENvF4VCgSx1cZlizY0NYap4cRwRERG9nap8cu3r64uQkBCMHDkSU6ZMEcvNzMwAQO8IckFBgSRGu7pISaPNBQUFYqz2cZmZmSXGPlsnvf3yijSIunq/TLHd7erB1MSwgltERERElaVKTwvx8/NDQEAAhgwZgkWLFkm21atXD8D/Tf14lrZMOw2kVq1aqFatmt5YtVqNrKwssT5t3SVN/UhPTy9xyggRERERvd2qbHLt5+cHf39/DB48GMuWLdO5yYtSqYSJiQnOnz+v81htmaOjIwDAwMAADg4OuHz5sk7CHB8fD0EQxFjt4zQaDeLj4yWxBQUFSEpKksQSERERUdVRJZNrf39/+Pv7Y+DAgVi+fLneG7ZUr14d3bt3R0xMDJKSksTyJ0+eYPv27WjWrJlktQ8PDw/k5eUhLCxMUk9gYCCMjIzEpf6Ap8v+KRQKBAYGSmK3bt2KvLw8rnFNREREVEVVuTnXmzZtgp+fHxo2bIguXbpg3759ku1169bF+++/DwCYM2cOzp49i4kTJ2LChAmoXr06tm3bhvT0dKxbt04y2j18+HDs2LED33//PVJTU2Fra4vjx4/j8OHDmDp1Kho3bizGqlQqjB07FiEhIZg+fTq6du0q3qHRxcWFyTURERFRFVXlkmvtGtJ3797FvHnzdLa7uLiIyXXTpk2xefNmrFq1CuvXr0dhYSEcHBzw22+/SW59DjxdKWTjxo3w9fVFeHg4srOzYWNjg2+//RZjx47V2c9XX32FRo0aISwsDMeOHYOlpSU8PT0xY8YM3vqciIiIqIpSCIIgVHYjSL/CwmJkZ+dWdjP0ylIX42hSxosDAbi1sirzahoVFfumtKO7XT1YcrUQIiKit46Vle4dwPWpciPX9PIKBCC3sGzrNRfzJxkRERGRDibXJMotLN9oNBERERFJcfIvEREREZFMmFwTEREREcmEyTURERERkUyYXBMRERERyYQXNBK9RgqFAlnqsq3IYm5sCFPFi+OIiIjozcHkmug1yivSlGtNbFOuiU1ERPRW4bQQIiIiIiKZMLkmIiIiIpIJk2siIiIiIpkwuSYiIiIikgmTayIiIiIimTC5JiIiIiKSCZNrIiIiIiKZMLkmIiIiIpIJk2siIiIiIpnwDo1EbyjeKp2IiOjtw+Sa6A3FW6UTERG9fTgthIiIiIhIJkyuiYiIiIhkwuSaiIiIiEgmTK6JiIiIiGTC5JqIiIiISCZcLYSoCuCyfURERG8GJtdEVQCX7SMiInozcFoIEREREZFMmFwTEREREcmEyTURERERkUyYXBMRERERyYTJNRERERGRTLhaCNE7pjzL9gFcuo+IiKg8mFwTvWPKs2wfwKX7iIiIyoPTQoiIiIiIZMKRayIqFe/+SEREVHZMromoVLz7IxERUdlxWggRERERkUyYXBMRERERyYTTQohINpyfTURE7zom10QkG87PJiKidx2TayKqFBzlJiKiqojJNRFVCo5yExFRVcTkmojeeBzlJiKitwWTayJ645VnlLuHvTVyBaFMsRWZiBcIQG4hfxAQEb1rmFwTUZXypkw3yS0sxtGkjEpvBxERvV5MriuQRqNBUFAQtmzZgtTUVNSpUwf9+vXDjBkzYG5uXtnNI3rnlWe6CQCYGBlCXVS2+OKyDZ4TEVEVw+S6Ai1fvhzBwcHo3bs3Jk6ciGvXriE4OBiJiYnYuHEjDAx4Dx+iylSeUW4AcGtlVeZ4t1ZWZa6Xc8qJiKoOJtcV5OrVqwgJCUGfPn3g5+cnljdu3BhLly7F/v37MWDAgEpsIRG9Kd6UqSxERPTqOHRaQcLDwyEIAsaPHy8pHzFiBMzMzLB3795KahkRERERVRSOXFeQixcvwsDAAG3btpWUm5qaws7ODgkJCZXUMiJ6m3EKCRHRm00hCGVcs4rKZcCAAcjMzMSZM2d0tn3xxReIiIhAQkICTExMKqF1RERERFQROC2kguTl5ZWYOJuamgIA8vPzX2eTiIiIiKiCMbmuIGZmZlCr1Xq3FRQUAACqVav2OptERERERBWMyXUFqVevHrKysvQm2Onp6bC0tOSUECIiIqIqhsl1BXF0dIRGo0F8fLykvKCgAElJSXB0dKyklhERERFRRWFyXUH69+8PhUKBwMBASfnWrVuRl5fHNa6JiIiIqiCuFlKBlixZgpCQEPTu3Rtdu3YV79Do7OyMwMBA3qGRiIiIqIphcl2BiouLERgYiLCwMKSmpsLS0hL9+/fHjBkzUL169cpuHhERERHJjMk1EREREZFMeIfGd5RGo0FQUBC2bNmC1NRU1KlTB/369cOMGTNgbm5e2c17J6lUKr3l5ubmiIuLk5Rdv34dq1atQmxsLAoLC+Hg4AAfHx+4ubnpPP7x48fw9fXFoUOHkJ2dDRsbG4wdOxajR4+GQsHb95XXunXrcOnSJVy6dAl37txBo0aNcOTIkRLjL1y4gNWrV+PChQtQKBRwcnLC3LlzYW9vrxObnp6O//znPzhx4gRyc3PRsmVLTJo0Cf369dOJVavVCAgIwJ49e5CRkYH69etjyJAhmDRpEoyNjWU95qqkPP03f/587Nq1S++2NWvWwN3dXVJW3j7ZvXs3Nm7ciOvXr8PCwgLdu3fHnDlzUKdOnVc/0Crqxo0b2Lt3L06fPo2UlBQUFBTAxsYG7u7uGD9+vM73V0V9VvI79OWUp//8/Pzg7++vt57/+Z//wWeffSYpK2+fHD9+HAEBAUhKSoKJiQk6d+6ML7/8Ek2aNHnl42Ry/Y5avnw5goOD0bt3b0ycOFGcD56YmIiNGzdyPngl6dixI0aMGCEpe/5LOSUlBaNHj4ahoSG8vb1hYWGBbdu2wdvbG7/++iu6dOkixqrVanh5eeHy5cvw9PSEra0tTpw4gUWLFiEzMxM+Pj6v5biqkp9++gm1a9eGg4MDHj9+XGrs+fPnMW7cOFhbW+OLL74AAISEhGDMmDHYsmWL5AdVdnY2xowZgwcPHmDChAmoX78+wsPDMXPmTOTm5mLo0KGSumfOnInIyEgMHToUTk5OiIuLw5o1a5CSkoLvv/9e/gOvIsrTf1orV67UKWvbtq1OWXn6ZOPGjVixYgVcXFzw9ddfIy0tDRs3bsT58+exbds2Jmgl2LFjBzZt2oQePXpgwIABMDIyQnR0NHx9fXHw4EFs3bpVvIdERX5W8jv05ZSn/7QWLFgAS0tLSZm+FdfK0yeHDh3CjBkzYGdnhy+//BI5OTkIDAzE6NGjsWPHDlhbW7/agQr0zrly5YqgUqmE6dOnS8qDgoIEpVIp7N27t5Ja9m5TKpXCvHnzXhg3Y8YMwc7OTkhMTBTLcnJyhG7dugl9+vQRNBqNWB4SEiIolUohKChIUsf06dOF1q1bC3fu3JHvAN4RKSkp4r8//vhjoXv37iXGDh06VHBychLS0tLEsrS0NMHJyUnw8vKSxP7www+CUqkUIiMjxbKioiJh6NChgouLi5CTkyOWHzt2TFAqlcKKFSskdaxYsUJQKpXC33///dLHV9WVp//mzZsnKJXKMtVbnj7JzMwU2rVrJwwdOlQoKioSyyMjIwWlUikEBASU9XDeOfHx8cKjR490yn/66SdBqVQKwcHBYllFfVbyO/Tllaf/fv75Z0GpVAq3b99+Yb3l6RO1Wi188MEHQrdu3SSfq4mJiYKdnZ3wzTffvMyhSfCn1TsoPDwcgiBg/PjxkvIRI0bAzMwMe/furaSWEfB0BOXJkyd6t+Xm5uLIkSNwcXGRTCuoXr06hg0bhps3byIhIUEsDw8Ph5mZmc5o+Pjx41FYWIgDBw5UzEFUYWU9ZXjr1i0kJCTA3d1dMgpibW0Nd3d3nDlzBvfv3xfLw8PDYWNjgx49eohlhoaG8PT0RHZ2No4fPy6W79u3DwB03sPav/keLtnLnPIVBAE5OTnQaDQlxpSnTyIjI5GXlwdPT08YGhqK5T169ECTJk3Yf6Vo06YNatSooVPev39/AMCVK1cAVOxnJb9DX15Z++95OTk5KCoqKrHe8vRJbGwsMjIyMGzYMMniEvb29nBxccGBAwdQWFhYruN6HpPrd9DFixdhYGCgc1rT1NQUdnZ2kg8cer3++9//on379nB2doabmxuWLFkiOXWdnJwMtVqN9u3b6zxWW6btP41Gg8TERNjb28PU1FQS27ZtWygUCvZ1BdI+t05OTjrb2rdvD0EQcOnSJQBARkYG0tPT0a5dO72xz9an/be1tTUaNGggiW3QoAHq1avHfpVZhw4d0KFDB7Rt2xZeXl64cOGCTkx5+qS010a7du1w/fr1En9gk35paWkAgLp16wKo2M9KfofK7/n+e9Ynn3wivv9GjRolGWjQKk+fvOizOScnBzdv3nyVw+Gc63dRRkZGibdft7a2RlxcHNRqNW/P/pq1bdsW7u7uaNq0KXJycnD8+HGEhIQgJiYGW7ZsQfXq1ZGRkQEAeueDacvS09MBAA8fPkR+fr7eWBMTE1haWor1kfy0z229evV0tj3fV2Xp12f7KiMjAy1bttS7X2tra/GLil5N3bp1MWHCBLRu3Rrm5uZISkpCYGAgxo4di/Xr10vm7JanT17U34IgICMjA82bN5f5iKqm4uJiBAQEwMjICB4eHgDK9p562c9KfofKS1//AUCNGjUwcuRIODk5oWbNmrhx4wYCAwMxZcoULF++HEOGDBFjy9Mnpb02tJ/X6enpaNWq1UsfE5Prd1BeXl6Jb3rtr/b8/Hx+MLxm27Ztk/w9aNAgqFQqrF69GkFBQZg6dSry8vIAQG/faPtOG5Ofn19irDZeG0vyK62vtGVl6avn+1UbX1q/auujVzN37lzJ37169YKHhwcGDRqEhQsX4tChQ+K28vRJWd7H7MOyW758OeLi4jB79my0aNECQNme45f9rOR3qLz09R8ATJgwQSd26NChGDBgAFasWIG+ffuK0zrK0yev4/3HaSHvIDMzM6jVar3bCgoKAEDnal2qHJ999hmMjY3F02BmZmYAoLf/tH2njdH2YWl9rY0l+ZXWV9qysvTV8/2qjS+tX/n+rTjNmjVDv379cOvWLdy4cUMsL0+flOV9zD4sG19fX4SEhGDkyJGYMmWKWF6Rn5X8DpVPSf1XEktLS4waNQqPHj2SLFFbnj55He8/JtfvoHr16iErK0vvCys9Pb3EUyv0+hkbG4v9BUhPWT1PW6Y91VWrVi1Uq1ZNb6xarUZWVpbeKQskD+1zq2/qzfN9VZZ+fbav6tWrpzdWG//Ky0hRqRo1agQA4vsSKF+fvKi/FQoF35tl4Ofnh4CAAAwZMgSLFi2SbKvIz0p+h8qjtP4rTUnvv7L2SWmvjdKmjJQHk+t3kKOjIzQaDeLj4yXlBQUFSEpK0rt+JFWOgoICpKen47333gMAKJVKmJiY4Pz58zqx2jJt/xkYGMDBwQGXL1/W+cCJj4+HIAjs6wrUpk0bANC5ARDwtK8UCgVat24N4OmHvbW1td4L5bT9qq1P++/09HTcu3dPEnvv3j1kZGSwXyuY9mKnZy++Kk+flPbauHDhApo3by5ZxYB0aW8wMnjwYCxbtkznJi8V+VnJ79BX96L+K42+9195+uRFn80WFhZo1qxZOY5GF5Prd1D//v2hUCgQGBgoKd+6dSvy8vIwYMCASmrZu+vZX+DP8vX1RVFREbp37w7g6TJS3bt3R0xMDJKSksS4J0+eYPv27WjWrJnkamkPDw/k5eUhLCxMUm9gYCCMjIzE5Y9Ifk2bNoWjoyMiIiIkIyTp6emIiIhA586dYWVlJZZ//PHHSElJkdwtsLi4GCEhIahZsyY++ugjsVx70c/z72Ht33wPv7rc3FzxFPGzEhMTERERAVtbW9jY2Ijl5emTnj17olq1ati0aROKi4vF8iNHjuD27dvsvxfw9/eHv78/Bg4ciOXLl+u9YUtFflbyO/TVlKX/ioqK9N7k6d69e9iyZQtq164tWe2jPH3SqVMnWFlZYfv27ZJVeZKSkhATEwN3d/dXvsut4cKFCxe+Ug301qlbty6ysrKwa9cuJCcn48mTJ9i3bx/Wrl2Ljh07Yt68ebwt9mu2evVq+Pv74/bt27h58yZiYmLg6+uL8PBwtGvXDgsXLoSR0dPrjx0cHLBnzx7s27cPxcXFSEpKwpIlS5CSkoIff/wRTZs2Feu1s7PDiRMnsGfPHjx+/Bj37t1DQEAADh8+jClTpqBPnz6Vdchvrd27d+PIkSOIjY1FdHQ08vLyUFRUhNjYWKSmpsLOzk6MbdWqFbZv345Dhw5Bo9Hg/PnzWLhwIXJzc+Hr6ysZeWndujUOHjyIPXv2QK1W4+bNm1i5ciXi4uLw7bffSr5ImjVrhkuXLmHXrl1IS0vDgwcPEBoaitDQUHzyySd6LwSip8raf//88w+GDRuGW7du4ebNm0hOTsb27duxePFiGBoawtfXFw0bNhTrLU+fmJmZwdTUFDt37hRvy33kyBH88MMPaNKkCZYvX85pBSXYtGkTfvzxRzRs2BDDhw/HlStXkJycLP6XmZkp/uipqM9Kfoe+vLL2X05ODnr27IkbN27gxo0buHbtGsLDw/HNN9/gyZMnWLFihWT98vL0iaGhIRo0aIDt27fjxIkTKC4uxtmzZ7Fo0SKYm5vjp59+goWFxSsdp0IQBOGVaqC3UnFxMQIDAxEWFobU1FRYWlqif//+mDFjBk9HVoI///wTmzdvxpUrV5CdnQ1DQ0M0bdoU/fr1g5eXl87aq9euXcOqVavEL2YHBwf4+PhIlgbTevToEXx9fXHo0CFkZ2fDxsYGY8aMwdixY/kF8BLGjRuHmJgYvdtcXFwQHBwsKYuLi4Ovr694utLZ2RmzZ88Wp4Q8Kz09HatWrcKJEyeQm5uLli1bYtKkSXrPMBQUFGDt2rXYt28fMjIyYG1tjSFDhmDy5MmvPOpSlZW1/+7fv4+VK1ciISEBGRkZKCgogJWVFVxdXTF58mTY2trqPL68fbJz505s3LgRN27cgIWFBbp164a5c+eK08BI1/z587Fr164Stz//Hqyoz0p+h76csvafWq3GokWLEB8fj7S0NOTm5sLS0hLOzs7w9vbWWc8aKH+fHD16FAEBAUhOToaJiQnc3Nwwd+5cyRmpl8XkmoiIiIhIJpxzTUREREQkEybXREREREQyYXJNRERERCQTJtdERERERDJhck1EREREJBMm10REREREMmFyTUREREQkEybXREREREQyYXJNRERERCQTJtdERERERDJhck1EREREJBMm10REREREMmFyTUREREQkEybXREREREQyYXJNRERERCQTJtdERERERDJhck1EREREJBMm10REREREMmFyTURVmkqlwrhx4yq7GSXauXMnVCoVdu7cWdlNeWV37tyBSqXC/PnzZa33559/Rps2bXDv3j1Z65VbQkICvLy84OrqCpVKhYEDB1Z2k2T3Ku+nixcvQqVSYdu2bTK3iujNYlTZDSCiqkGlUkn+NjAwQI0aNaBSqTB48GAMHjwYCoWiklpHclGpVHBxcUFwcPBr2d+9e/fw+++/Y+TIkWjQoEGpsfn5+ejUqRPGjBmDBQsWAAC+/fZb7N+/HzExMTAyqrivvJycHEyZMgUFBQUYOHAgLC0tUbdu3Qrb39vI0dERvXr1wpo1a9C/f39Ur169sptEVCGYXBORrKZPnw4AKCoqwq1bt/Dnn38iJiYGFy9exP/7f//vtbfnwIEDMDMze+37JXmsXbsWarUa3t7eL4w9d+4c1Go1OnfuLJZFRUWhU6dOFZpYA0B8fDwyMzMxa9YsfP755xW6r7fZlClTMHz4cAQHB/N5oiqLyTURycrHx0fy999//w1PT0+EhobCy8sLTZo0ea3tsbW1fa37I/k8fvwY+/btg5ubG+rXr//C+LNnz8LQ0BCdOnUC8HSayu3btzF27NiKbioyMjIAAPXq1avwfb3N2rZtixYtWiAsLAyTJ0+GgQFnp1LVw1c1EVWoDh06oEWLFhAEAZcuXdIbc/LkSUyaNAmurq7iqeMffvgBjx49EmMKCgrQsWNHuLm5oaioSG893333HVQqFY4ePSqWlTRHtKioCJs2bcKIESPg7OyMdu3aYdCgQQgJCYFGoxHjnjx5AkdHR4waNUry+Pz8fLRp0wYqlQq7d++WbAsNDYVKpcL27dtf/ASVIi0tDYsXL0bPnj3h6OgIV1dXfP7554iPj9eJ9fPzg0qlQnR0NCIiIjBs2DC0a9cOLi4umDVrFtLT0/XuIz4+HhMnToSTkxOcnZ0xYcIExMXFSeoD/m9uOADExMRApVKJ//n5+enUe+fOHcyaNQuurq5o06YNhgwZIumXsggPD0deXh769eund3tOTg5u3bol/nfq1CnY2toiMzMTt27dwsGDBwEAjRs3FmPy8/PLvP+oqCh89tlncHFxgaOjI/r27YtVq1bh8ePHkuNUqVSYN28eAGDBggXi81LaPPrr169DpVJhzpw5kvLbt2+Lj//rr78k23788UeoVCpERUVJyi9evAgfHx+4ubnB0dER3bt3x8KFC8WE/1nz58+HSqXC7du3ERwcjAEDBqBt27aS94harcYvv/yCXr16wdHRET169MDq1auhVqv1HktOTg5++eUXeHh4wNnZGU5OTujVqxdmzpyJixcv6sR//PHHuHv3Lk6fPl3i80P0NuPINRG9NvpOzfv7+8PPzw+1a9dGt27dUKdOHVy5cgUbNmzAiRMnEBYWBgsLC5iamqJ///4ICwvDiRMn0KNHD0k9arUaBw8eRN26dfHhhx+W2o7CwkJ8/vnnOHXqFJo3bw4PDw+YmpoiOjoaS5YswYULF/Djjz8CAKpXr442bdogPj4eOTk5sLCwAPB/UxCApyOmgwYNEus/e/YsAMDNze2ln6tLly5h4sSJePjwIT744AP06dMHWVlZ+PPPPzFmzBj88ssv6Nq1q87jQkNDceTIEfTo0QOdOnVCfHw8Dhw4gKSkJOzZswcmJiZibGxsLCZOnAiNRoPevXvDxsYGV65cwaeffiqZWgEA9vb2mD59Ovz9/dGoUSMMHjxY3Obi4iKJTU1NxfDhw9GkSRMMHDgQDx8+xIEDBzBt2jT88ccfOnWXRJtEdujQQe/2Q4cOiXOrn9WnTx/J39qpSgAQFBQEV1fXF+57y5YtWLhwIczMzODu7o733nsPMTEx+PXXX3H06FFs3rwZNWvWRM2aNTF9+nRcvnwZkZGR6NmzJ+zt7QFA/L8+LVq0gLW1tfjjRUv72gGeHn/Hjh0lf5uamsLZ2VksO3r0qHi2qG/fvmjYsCEuXbqEzZs3IzIyEqGhoXrPFi1btgx//fUXunbtiq5du8LQ0BAAIAgCZs6cicjISNjY2MDT0xOFhYXYsWMHrly5olOPIAjw9vZGXFwcnJycMHz4cBgaGiI9PR3R0dHo2LEjHB0dJY/Rtv/MmTMvfK8SvZUEIiIZKJVKQalU6pTHxMQIdnZ2QuvWrYX09HTJtqioKEGpVAojR44UHj58KNm2Y8cOQalUCsuWLRPLzp07JyiVSsHHx0dnPwcOHBCUSqWwYsUKnXZ5enpKyn7++WdBqVQKixcvFoqKisTyoqIiYcGCBYJSqRQOHz4slvv6+gpKpVI4evSoWLZq1SrB3t5e+PTTT4WPPvpILC8uLhZcXFyEnj176nuadGiPc8eOHWJZYWGh0KtXL8HR0VGIjo6WxKelpQkffPCB8P777wsFBQU6x+Tk5CQkJSVJHjN79mxBqVQK+/fvl7Szd+/eglKpFI4dOyaJDw0NFfvz7Nmzkm36nk+t27dvi4/z8/OTbDtx4oSgVCoFb2/vMjwrT3Xp0kVwdnYWNBqN3u137twRDh48KBw8eFBYvny5oFQqBX9/f7GsXbt2wrhx48S/Dx48KGRmZr5wv3fu3BFat24tODk5Cf/8849k23fffScolUrhm2++kZTr68cX+fLLLwWlUilcuXJFLJs1a5bg6uoqDBw4UBg9erRYnp2dLdjZ2QmffvqpWJaTkyO4uLgIdnZ2QmxsrKTudevWCUqlUvDy8pKUz5s3T1AqlcIHH3wgpKSk6LRp7969glKpFEaMGCHk5+eL5VlZWULPnj11+j8pKUlQKpXCtGnTdOoqLi4WsrOzdcofPXokKJVKYejQoaU9be8mRAAADKlJREFUPURvLU4LISJZ+fn5wc/PD6tXr8bMmTPh5eUFQRAwb948nfmo2hUnlixZgpo1a0q2DRkyBPb29ti3b59Y5uTkhGbNmuHIkSPIzs6WxGunZjw7gqyPRqNBSEgIrKyssGDBAnHEDgAMDQ0xf/58KBQKyX61I9DPno6PiopC69at0adPH6SlpeHGjRsAgMuXLyM7O/uVRq2PHTuGlJQUeHp66owKW1tbw9vbG/fv39eZHgAA48aN01m5Zfjw4QCeLhWnde7cOdy6dQuurq46I+AjR45Es2bNXrr9jRo1wtSpUyVlH374IRo2bKh3Sos+arUa//77L+rWrVviKjONGjWCu7s73N3doVAoYGxsDC8vL7i7u0OlUiEvL0/crv2vTp06L9z33r17UVhYCE9PT505+7NmzUL16tWxZ8+eEqdJlJW+19XZs2fRuXNnuLm5IT4+Hrm5uQCA6OhoaDQayesqMjIS2dnZ6N+/v2SEGwAmTpyIRo0a4fTp07h7967Ovr29vfWOaGunssyaNQumpqZiee3atTFt2rQSj6VatWo6ZQYGBqhVq5ZOeY0aNWBqavrGL61I9LI4LYSIZOXv7y/5W6FQYNmyZRg6dKhO7Pnz52FsbIyIiAhERETobC8sLMSDBw+QlZUFS0tLAMDgwYOxevVq7N+/X7xQ7d9//8WpU6fg4OAAOzu7Utt348YNZGdno1mzZggICNAbU61aNVy/fl38u3379qhWrZqYBD1+/BiJiYnw9vYWpzhERUWhefPm4mn9sk590Of8+fMAgLt37+qdz3zz5k0AwLVr13QS4zZt2ujEa5ewe/jwoVh2+fJlAPqnXBgYGMDZ2VncT3nZ2dlJfrRo1a9fXzy2F9H+eHr+R1dJzp49C0dHR5ibmwN4OuUF0J2yUhaJiYkA9PdhrVq14ODggNjYWFy/fv2Fr7fSPPva+fTTT3HlyhVkZmaKF3Bu2LABsbGx6Nq1q97XVWntNDIyQqdOnZCamorExEQ0bNhQsr1t27Z625SYmAgDAwO9rwt9z2XLli1hb2+P8PBwpKamomfPnujQoQMcHR0lU5CeV6tWLWRmZpa4nehtxuSaiGSVnJwMAMjNzcX58+fx9ddf47vvvkPDhg11RnOzs7NRVFSkk5A/Lzc3V0yuBw0ahDVr1mD37t1icr1v3z4UFRW9cNRau0/gaYJa2n6fPHki/tvExAQdOnTAmTNn8ODBA5w7dw7FxcVwc3ODra0trKyscPbsWYwZMwZRUVFQKBSvlFxr26jvB8eztKOaz6pRo4ZOmTbRffZCTe1FeSWtxfzee++VrbF6lJQQGxkZSdpQGu1IaEFBgd7t0dHRiImJAfD0uJKSkuDo6Cj+GDl+/DgMDQ3FixoB3ZVsSqJ9bqysrPRu15Y/e8Hty2jQoAGaNWuG2NhYFBcXiz/e3NzcULduXRgbG+Ps2bPo2rUroqKiYGFhIfnxVNZ2PnsBplZJ/f748WPUqlULxsbGJdb3LENDQwQGBuKXX37Bf//7X6xatQrA02sVBg8ejNmzZ+tdz7qgoEAyMk5UlTC5JqIKYW5uji5duiAgIABDhgzB/PnzERERIVlz2sLCAoIgiElSWdSvXx+dO3fGmTNncO3aNdja2mLXrl0wNjbGgAEDXvh4bfLZu3fvFyb1z+rcuTNOnz6NqKgoxMXFSS4s69y5M06ePAm1Wo2///4brVq1eqXkVNvGtWvXomfPni9dT2m0F2b++++/erdX9qhizZo1YWxsrDP9RysmJkan/xISEiRTXwDpmZSyJtfa5//ff/9Fq1atdLbfv39fEvcqXF1dERYWhoSEBERFRaFRo0awsbEB8PQsxJkzZ5Ceno7r16+je/fukjMC2v1r21OedpY01aZGjRp4+PAhCgsLdRLskvZTq1YtfPXVV/jqq69w69YtxMTEICwsDCEhIXj06JF4cbCWRqPBo0eP0LhxY731Eb3tOOeaiCqUnZ0dhg8fjrS0NGzcuFGyrX379nj48CGuXr1arjq1K1Xs3r0bly9fRnJyMj788MMyzadt0aIFatasifPnz6OwsLDM+3z2FP7Zs2fh5OQkjry5ubkhOzsboaGhyM3NfaVRawBo164dAOgsxSYnBwcHAE/XIX+eRqPBuXPn9D7OwMAAxcXFFdauZymVSty/fx85OTk623x8fJCcnIzk5GRMnDgRJiYmiI+PR3JyMg4cOAAAWLhwoRijPaNSFtpVPp5fyQN4Olp9+fJlmJqayrKGuvZszqlTp/DXX39JXjtubm5ITk4WR9/1reACQO+P06KiIvH1o+3rsnBwcIBGo9H7uijLj+CmTZti+PDhCAkJgbm5OSIjI3Vibty4AUEQSl1NhehtxuSaiCrctGnTYGJigg0bNkjm/U6YMAHA01tU61uHWTu15Hl9+vSBhYUF9u7dK16ANWTIkDK1xcjICJ6enrh//z6WLl2qd93jjIwM/PPPP5Ky1q1bo0aNGoiMjMTVq1clU1y0Sc/69eslf7+snj17wsbGBqGhoTh+/LjemLi4OOTl5b30PpydnWFjY4Po6GidfYSFhZU437p27dpIS0t76f2Wh6urKzQazQsvgoyOjkb79u3FHzvaJPBl5lsDwCeffAJjY2OEhITg1q1bkm1r1qxBTk4OPvnkk1LnFJeVq6srFAoFQkND8fjxY53XlSAIJb6uevXqhdq1a2P//v0675PAwEDcuXMHXbp00ZlvXRrt+8jX11cyJSc7O1vvNQq3b9/G7du3dcq1o9/6LnTUtrUsSyISvY04LYSIKpy1tTVGjRqFoKAg/Pbbb+KNM9zc3DBnzhz89NNP6Nu3Lz766CM0btwYubm5uHv3LmJjY+Hs7Izff/9dUl+1atXg7u6O7du3Y/Pmzahdu7beNZ9LMm3aNCQlJWHLli04evQoOnfuDGtra/HmI+fOncOsWbPQsmVL8TGGhoZwcXERR+KeTYK0p/JTUlLEuFdhbGwMPz8/eHt7Y/LkyXBycoK9vT2qVauGtLQ0JCQk4Pbt2zh16tRL39rdwMAAS5cuhbe3N6ZNm4Y+ffrAxsYGycnJOH36ND766COcOHFC5w56bm5u2L9/Pz7//HM4ODiIF85p74oopz59+mDDhg04efIkunTpojdGO5L87EoWMTExsLKyeumR5caNG2PBggVYvHgxBg8ejH79+qFOnTqIjY1FXFwcWrRogblz575U3c+rU6cOVCoVkpKSAEgT6Pbt28PMzAyZmZli3LOqV6+OZcuWYebMmfD09IS7u7u4zvWpU6dgZWWFxYsXl6s9Hh4eOHDgAI4cOQIPDw/07NkTRUVFiIiIQJs2bZCSkiKJT05OxvTp09GmTRvY2tqiXr16ePDgASIjI1FYWIhJkybp7OP06dMwNDSssClPRJWNI9dE9FpMmTIFZmZmCA4OlszznTx5MkJCQtC1a1ecO3cOQUFBiIiIQHp6OkaMGIGZM2fqrU87NaSwsBAeHh7lGkU0NjbG2rVr8cMPP6B58+Y4duwY/vjjD5w8eRIajQZffPGF3vnb2oTawsJC58YY2m3aEe5XZWdnhz179mDSpEnIycnBzp07sWXLFly6dAkODg5YuXKleJHny3J1dUVISAhcXFxw7NgxBAUFIT8/H0FBQeIybdq52Vpff/01PDw8EB8fj4CAAKxZs0Zy4xM5aX9U7Nu3r8SpKDExMdBoNJIfNLGxsa+c7I8dOxa///472rdvj0OHDuGPP/5AZmYmPvvsM4SFhaF27dqvVP+ztK+dli1bSi4a1F5IC/zfCPfzevXqhdDQUHTt2hWnTp3Chg0bcO3aNYwaNQo7duzQu9xeaRQKBdasWQMfHx9x2cojR45g6NChWLNmjU68o6MjJk+eDENDQ5w8eVK8+VPr1q2xfv16eHl5SeIfP36MP//8E926dRNXsSGqahSCIAiV3QgiInqzjBo1CvHx8fjrr7/E5e0qQ3h4OObMmQN/f3/07t270tpB8ggODsbSpUuxadMmnbW5iaoKjlwTEb2j8vLy9C4nt3PnTsTFxeH999+v1MQaAD7++GO0a9cOfn5+4FjQ2y0/Px/r1q1D3759mVhTlcY510RE76i7d+9i8ODB6NKlC5o2bYri4mIkJibi77//Rs2aNTF//vzKbiIUCgUWL16Mw4cPIyMjA9bW1pXdJHpJqampGDlypDili6iq4rQQIqJ31MOHD7Fy5UrExsbi/v37KCwsRN26deHm5oapU6eK6y0TEVHZMbkmIiIiIpIJ51wTEREREcmEyTURERERkUyYXBMRERERyYTJNRERERGRTJhcExERERHJ5P8D+lZ7SCoZbYQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 792x792 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of review length distribution\n",
    "\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.25, .75)}, \n",
    "                                    figsize=(11,11), edgecolor ='k')\n",
    "\n",
    "sns.boxplot(lengths, ax=ax_box)\n",
    "sns.distplot(lengths, kde=False, norm_hist=False, ax=ax_hist)\n",
    "\n",
    "ax_hist.set_xlabel('Review length (# of words)', fontsize=20, labelpad=15)\n",
    "ax_hist.set_ylabel('Frequency', fontsize=20, labelpad=13)\n",
    "ax_hist.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax_box.set_yticks([])\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=.05)\n",
    "plt.savefig('fig1.eps', dpi=300, format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for returning an original review from an encoded training/test set instance\n",
    "\n",
    "def display_review(encoded_review):\n",
    "    print(' '.join(id2word[idx] for idx in encoded_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "# Example review\n",
    "\n",
    "display_review(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline model: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert dataset to words and to counts for use with Scikit-Learn\n",
    "\n",
    "def indices_to_words_counts(train, test):\n",
    "    \"\"\"Converts dataset consisting of list of lists of indices into list of lists of words and \n",
    "    list of lists of word counts. The binary arg can be set to True for generating vectors of \n",
    "    word presence rather than word occurence count.\"\"\"\n",
    "    \n",
    "    # Filter out indices less than 3 (the index 1 is the start_char, 2 is the oov_char, 3 is never used)\n",
    "    filtered_train = [list(filter(lambda x: x > 3, rev)) for rev in train]\n",
    "    filtered_test = [list(filter(lambda x: x > 3, rev)) for rev in test]\n",
    "    \n",
    "    # Only retain the first 500 words in a review.\n",
    "    filtered_train = [rev[:500] for rev in filtered_train]\n",
    "    filtered_test = [rev[:500] for rev in filtered_test]\n",
    "              \n",
    "    # Map indices back to words    \n",
    "    X_train_words = [' '.join(review) for review in [list(map(id2word.get, rev)) for rev in filtered_train]]\n",
    "    X_test_words = [' '.join(review) for review in [list(map(id2word.get, rev)) for rev in filtered_test]]\n",
    "    \n",
    "    # Generate BoW vectors\n",
    "    count_vec = CountVectorizer(tokenizer=nltk.word_tokenize, binary=False)\n",
    "    X_train_counts = count_vec.fit_transform(X_train_words)\n",
    "    X_test_counts = count_vec.transform(X_test_words)\n",
    "    \n",
    "    bin_vec = CountVectorizer(tokenizer=nltk.word_tokenize, binary=True)\n",
    "    X_train_bin = bin_vec.fit_transform(X_train_words)\n",
    "    X_test_bin = bin_vec.transform(X_test_words)\n",
    "    \n",
    "    return (X_train_words, X_train_counts, X_train_bin), (X_test_words, X_test_counts, X_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to words and count\n",
    "\n",
    "(X_train_words, X_train_counts, X_train_bin), (X_test_words, X_test_counts, X_test_bin) = indices_to_words_counts(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix (adapted from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          filename=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=16)\n",
    "    plt.xlabel('Predicted label', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 0.031204938888549805\n",
      "Time to predict: 0.014931917190551758\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes classifier and make predictions\n",
    "\n",
    "start = time.time()\n",
    "mnb_clf = MultinomialNB().fit(X_train_counts, y_train)\n",
    "stop = time.time()\n",
    "print('Time to train:', stop - start)\n",
    "\n",
    "start = time.time()\n",
    "predictions = mnb_clf.predict(X_test_counts)\n",
    "stop = time.time()\n",
    "print('Time to predict:', stop - start)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "c_matrix_nb = confusion_matrix(y_test, predictions, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81912\n",
      "Recall: 0.77264\n",
      "Precision: 0.8518257188216617\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 9658  2842]\n",
      " [ 1680 10820]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(c_matrix_nb, ['+', '-'], title='', filename='fig4a.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 0.057852983474731445\n",
      "Time to predict: 0.033313751220703125\n"
     ]
    }
   ],
   "source": [
    "# Train Bernoulli Naive Bayes classifier and make predictions\n",
    "\n",
    "start = time.time()\n",
    "bnb_clf = BernoulliNB().fit(X_train_bin, y_train)\n",
    "stop = time.time()\n",
    "print('Time to train:', stop - start)\n",
    "\n",
    "start = time.time()\n",
    "predictions = bnb_clf.predict(X_test_bin)\n",
    "stop = time.time()\n",
    "print('Time to predict:', stop - start)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "c_matrix_bnb = confusion_matrix(y_test, predictions, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83804\n",
      "Recall: 0.81344\n",
      "Precision: 0.8555321834244847\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10168  2332]\n",
      " [ 1717 10783]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(c_matrix_bnb, ['+', '-'], title='', filename='fig4b.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.88352\n",
      "Best estimator: LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='hinge', max_iter=5000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Grid search on the C parameter\n",
    "\n",
    "params = {'C': [0.003, 0.01, 0.03, 0.1, 0.3]}\n",
    "\n",
    "svm_clf = LinearSVC(loss='hinge', max_iter=5000)\n",
    "grid = GridSearchCV(svm_clf, params, cv=5, scoring='accuracy').fit(X_train_counts, y_train)\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best estimator:', grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 0.9681868553161621\n",
      "Time to predict: 0.008473873138427734\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier and make predictions\n",
    "\n",
    "start = time.time()\n",
    "svm = LinearSVC(loss='hinge', max_iter=3000, C=0.01).fit(X_train_counts, y_train)\n",
    "stop = time.time()\n",
    "print('Time to train:', stop - start)\n",
    "\n",
    "start = time.time()\n",
    "predictions = grid.predict(X_test_counts)\n",
    "stop = time.time()\n",
    "print('Time to predict:', stop - start)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "c_matrix_svm = confusion_matrix(y_test, predictions, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88248\n",
      "Recall: 0.88472\n",
      "Precision: 0.8807741318891367\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[11059  1441]\n",
      " [ 1497 11003]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(c_matrix_svm, ['+', '-'], title='', filename='fig4c.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and quick look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, GRU, Embedding, MaxPooling1D, Dropout, Bidirectional, Conv1D\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate reviews at 500 words and pad shorter reviews with 0s \n",
    "\n",
    "max_length = 500 \n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_length) \n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test set into validation set and test set\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4472</td>\n",
       "      <td>113</td>\n",
       "      <td>103</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>5345</td>\n",
       "      <td>19</td>\n",
       "      <td>178</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>154</td>\n",
       "      <td>462</td>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "      <td>285</td>\n",
       "      <td>16</td>\n",
       "      <td>145</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>607</td>\n",
       "      <td>624</td>\n",
       "      <td>35</td>\n",
       "      <td>534</td>\n",
       "      <td>6</td>\n",
       "      <td>227</td>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>687</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7339</td>\n",
       "      <td>6</td>\n",
       "      <td>3693</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>7008</td>\n",
       "      <td>15</td>\n",
       "      <td>566</td>\n",
       "      <td>30</td>\n",
       "      <td>579</td>\n",
       "      <td>21</td>\n",
       "      <td>64</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7224</td>\n",
       "      <td>6</td>\n",
       "      <td>226</td>\n",
       "      <td>251</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3     4    5     6    7    8    9    ...    490  491   492  \\\n",
       "0    0    0    0    0     0    0     0    0    0    0  ...   4472  113   103   \n",
       "1    0    0    0    0     0    0     0    0    0    0  ...     52  154   462   \n",
       "2    0    0    0    0     0    0     0    0    0    0  ...    106  607   624   \n",
       "3  687   23    4    2  7339    6  3693   42   38   39  ...     26   49  7008   \n",
       "4    0    0    0    0     0    0     0    0    0    0  ...     19   14     5   \n",
       "\n",
       "    493  494  495   496  497  498   499  \n",
       "0    32   15   16  5345   19  178    32  \n",
       "1    33   89   78   285   16  145    95  \n",
       "2    35  534    6   227    7  129   113  \n",
       "3    15  566   30   579   21   64  2574  \n",
       "4  7224    6  226   251    7   61   113  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the padded sequences.\n",
    "\n",
    "df = pd.DataFrame(X_train)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have a subfolder in the main directory called glove.6B containing the contents of\n",
    "# the glove6B.zip file found here: http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dictionary of glove word embedding vectors\n",
    "\n",
    "def glove_embeddings(filename):\n",
    "    \"\"\"Generate dictionary of glove word embedding vectors from glove file.\"\"\"\n",
    "    \n",
    "    embedding = {}\n",
    "    with open('glove.6B/' + filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            embedding[line[0]] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(embedding, word2id, dim):\n",
    "    \"\"\"Creates a Keras Embedding() layer and loads in pre-trained GloVe vectors.\"\"\"\n",
    "    \n",
    "    vocab_len = len(word2id) + 1  # vocab_len should be all words plus 1 for padding\n",
    "    \n",
    "    all_embeddings = np.stack(embedding.values())\n",
    "    mean, std = all_embeddings.mean(), all_embeddings.std()\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_len, dim))\n",
    "    \n",
    "    for word, idx in word2id.items():\n",
    "        vec = embedding.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[idx, :] = vec\n",
    "        else:\n",
    "            embedding_matrix[idx, :] = np.random.normal(mean, std, size=dim)\n",
    "    \n",
    "    # Set the first four rows of the embedding matrix to all zeros\n",
    "    embedding_matrix[0:4] = 0\n",
    "\n",
    "    # Make Keras embedding layer\n",
    "    embedding_layer = Embedding(input_dim=vocab_len, output_dim=dim, trainable=True)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([embedding_matrix])\n",
    "    \n",
    "    return embedding_layer, embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to automate training/grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should have a subfolder in the main directory called saved_models containing the saved model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dropout, recurrent_dropout, optimizer, embedding=None, conv1d=False, bidirect=False, summary=True):\n",
    "    \n",
    "    if embedding is None:\n",
    "        dim = 100\n",
    "    else:\n",
    "        dim = dim = embedding.get_weights()[0].shape[1]\n",
    "    \n",
    "    model = Sequential() \n",
    "    if embedding is None:\n",
    "        model.add(Embedding(input_dim=12004, output_dim=dim, input_length=max_length))\n",
    "    else:\n",
    "        model.add(embedding)\n",
    "    if conv1d:\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "    if bidirect:\n",
    "        model.add(Bidirectional(LSTM(dim, return_sequences=False, \n",
    "                                     dropout=dropout, recurrent_dropout=recurrent_dropout)))\n",
    "    else:\n",
    "        model.add(LSTM(dim, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params):\n",
    "    \n",
    "    dropout = params['dropout']\n",
    "    recurrent_dropout = params['recurrent_dropout']\n",
    "    optimizer = params['optimizer']\n",
    "    embedding = params['embedding']\n",
    "    conv1d = params['conv1d']\n",
    "    bidirect = params['bidirect']\n",
    "    model_no = params['model_no']\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    model = build_model(dropout, recurrent_dropout, optimizer, embedding, conv1d, bidirect)\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='saved_models/weights.' + model_no + '.hdf5', \n",
    "                                   verbose=1, save_best_only=True)\n",
    "    \n",
    "    print('Training model', model_no)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, \n",
    "              batch_size=batch_size, callbacks=[checkpointer])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(parameters):\n",
    "    \n",
    "    columns = list(parameters[0].keys())\n",
    "    columns + ['train_acc', 'test_acc']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for params in parameters:\n",
    "        dropout = params['dropout']\n",
    "        recurrent_dropout = params['recurrent_dropout']\n",
    "        optimizer = params['optimizer']\n",
    "        embedding = params['embedding']\n",
    "        conv1d = params['conv1d']\n",
    "        bidirect = params['bidirect']\n",
    "        model_no = params['model_no']\n",
    "        batch_size = params['batch_size']\n",
    "        \n",
    "        model = build_model(dropout, recurrent_dropout, optimizer, embedding, conv1d, bidirect, summary=False)\n",
    "        model.load_weights('saved_models/weights.' + model_no + '.hdf5')\n",
    "        print('Evaluating training set accuracy on model', model_no)\n",
    "        _, train_accuracy = model.evaluate(X_train, y_train)\n",
    "        print('Evaluating test set accuracy on model', model_no)\n",
    "        _, test_accuracy = model.evaluate(X_test, y_test)\n",
    "        \n",
    "        params['train_acc'] = train_accuracy\n",
    "        params['test_acc'] = test_accuracy\n",
    "        df = df.append(params, ignore_index=True)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_params = params\n",
    "            best_accuracy = accuracy\n",
    "        \n",
    "    return best_params, best_accuracy, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Plain LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to be evaluated\n",
    "\n",
    "model_1 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'adam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '1',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_2 = {'dropout': 0.4,\n",
    "           'recurrent_dropout': 0.4,\n",
    "           'optimizer': 'adam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '2',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_3 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'adam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '3',\n",
    "           'batch_size': 64}\n",
    "\n",
    "model_4 = {'dropout': 0.4,\n",
    "           'recurrent_dropout': 0.4,\n",
    "           'optimizer': 'adam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '4',\n",
    "           'batch_size': 64}\n",
    "\n",
    "model_5 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '5',\n",
    "           'batch_size': 64}\n",
    "\n",
    "model_6 = {'dropout': 0.4,\n",
    "           'recurrent_dropout': 0.4,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '6',\n",
    "           'batch_size': 64}\n",
    "\n",
    "model_7 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '7',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_8 = {'dropout': 0.4,\n",
    "           'recurrent_dropout': 0.4,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '8',\n",
    "           'batch_size': 32}\n",
    "\n",
    "parameters = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 1\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 381s 15ms/step - loss: 0.4714 - acc: 0.7791 - val_loss: 0.4062 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40622, saving model to saved_models/weights.1.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 380s 15ms/step - loss: 0.3298 - acc: 0.8652 - val_loss: 0.3326 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40622 to 0.33256, saving model to saved_models/weights.1.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 381s 15ms/step - loss: 0.2968 - acc: 0.8807 - val_loss: 0.3583 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.33256\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 2\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 383s 15ms/step - loss: 0.5073 - acc: 0.7552 - val_loss: 0.4387 - val_acc: 0.8128\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43866, saving model to saved_models/weights.2.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 375s 15ms/step - loss: 0.3645 - acc: 0.8470 - val_loss: 0.4201 - val_acc: 0.8094\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43866 to 0.42011, saving model to saved_models/weights.2.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 375s 15ms/step - loss: 0.3340 - acc: 0.8594 - val_loss: 0.3845 - val_acc: 0.8412\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42011 to 0.38448, saving model to saved_models/weights.2.hdf5\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 3\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 210s 8ms/step - loss: 0.4753 - acc: 0.7747 - val_loss: 0.3667 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36672, saving model to saved_models/weights.3.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.3326 - acc: 0.8635 - val_loss: 0.3610 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36672 to 0.36096, saving model to saved_models/weights.3.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.3081 - acc: 0.8744 - val_loss: 0.3943 - val_acc: 0.8306\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36096\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 4\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 210s 8ms/step - loss: 0.5079 - acc: 0.7523 - val_loss: 0.3945 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39449, saving model to saved_models/weights.4.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.3724 - acc: 0.8427 - val_loss: 0.3940 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39449 to 0.39398, saving model to saved_models/weights.4.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.3308 - acc: 0.8656 - val_loss: 0.4695 - val_acc: 0.7766\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.39398\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 5\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 211s 8ms/step - loss: 0.5021 - acc: 0.7553 - val_loss: 0.4037 - val_acc: 0.8202\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40374, saving model to saved_models/weights.5.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 209s 8ms/step - loss: 0.4336 - acc: 0.8021 - val_loss: 0.3296 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40374 to 0.32955, saving model to saved_models/weights.5.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 210s 8ms/step - loss: 0.2436 - acc: 0.9026 - val_loss: 0.2971 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32955 to 0.29708, saving model to saved_models/weights.5.hdf5\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 6\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 209s 8ms/step - loss: 0.5092 - acc: 0.7543 - val_loss: 0.4566 - val_acc: 0.7874\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45656, saving model to saved_models/weights.6.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 207s 8ms/step - loss: 0.3664 - acc: 0.8471 - val_loss: 0.4040 - val_acc: 0.8282\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45656 to 0.40399, saving model to saved_models/weights.6.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.3271 - acc: 0.8626 - val_loss: 0.3701 - val_acc: 0.8430\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.40399 to 0.37008, saving model to saved_models/weights.6.hdf5\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 7\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 375s 15ms/step - loss: 0.5172 - acc: 0.7464 - val_loss: 0.4421 - val_acc: 0.8041\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44208, saving model to saved_models/weights.7.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 374s 15ms/step - loss: 0.3186 - acc: 0.8688 - val_loss: 0.2967 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44208 to 0.29668, saving model to saved_models/weights.7.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 374s 15ms/step - loss: 0.2160 - acc: 0.9161 - val_loss: 0.2923 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29668 to 0.29228, saving model to saved_models/weights.7.hdf5\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 8\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 377s 15ms/step - loss: 0.5252 - acc: 0.7394 - val_loss: 0.4152 - val_acc: 0.8206\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41523, saving model to saved_models/weights.8.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 375s 15ms/step - loss: 0.3706 - acc: 0.8422 - val_loss: 0.3678 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41523 to 0.36785, saving model to saved_models/weights.8.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 375s 15ms/step - loss: 0.2833 - acc: 0.8853 - val_loss: 0.3359 - val_acc: 0.8554\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36785 to 0.33593, saving model to saved_models/weights.8.hdf5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "# Warning: Running this code will re-train the models and overwrite the saved models.\n",
    "\n",
    "for params in parameters:\n",
    "    train_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 1\n",
      "12500/12500 [==============================] - 29s 2ms/step\n",
      "Evaluating model 2\n",
      "12500/12500 [==============================] - 29s 2ms/step\n",
      "Evaluating model 3\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating model 4\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating model 5\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating model 6\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating model 7\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating model 8\n",
      "12500/12500 [==============================] - 30s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>embedding</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>bidirect</th>\n",
       "      <th>model_no</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.86528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.84112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.84696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.83392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.87976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.84328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.86016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  recurrent_dropout optimizer embedding conv1d bidirect model_no  \\\n",
       "0      0.2                0.2      adam      None  False    False        1   \n",
       "1      0.4                0.4      adam      None  False    False        2   \n",
       "2      0.2                0.2      adam      None  False    False        3   \n",
       "3      0.4                0.4      adam      None  False    False        4   \n",
       "4      0.2                0.2     nadam      None  False    False        5   \n",
       "5      0.4                0.4     nadam      None  False    False        6   \n",
       "6      0.2                0.2     nadam      None  False    False        7   \n",
       "7      0.4                0.4     nadam      None  False    False        8   \n",
       "\n",
       "  batch_size  val_acc  \n",
       "0         32  0.86528  \n",
       "1         32  0.84112  \n",
       "2         64  0.84696  \n",
       "3         64  0.83392  \n",
       "4         64  0.87976  \n",
       "5         64  0.84328  \n",
       "6         32  0.88032  \n",
       "7         32  0.86016  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation summary\n",
    "\n",
    "best_params, best_accuracy, df = best_model(parameters)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Conv1D + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'adam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '9',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_10 = {'dropout': 0.4,\n",
    "           'recurrent_dropout': 0.4,\n",
    "           'optimizer': 'adam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '10',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_11 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'adam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '11',\n",
    "           'batch_size': 64}\n",
    "\n",
    "model_12 = {'dropout': 0.4,\n",
    "           'recurrent_dropout': 0.4,\n",
    "           'optimizer': 'adam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '12',\n",
    "           'batch_size': 64}\n",
    "\n",
    "model_13 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '13',\n",
    "           'batch_size': 64}\n",
    "\n",
    "model_14 = {'dropout': 0.4,\n",
    "           'recurrent_dropout': 0.4,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '14',\n",
    "           'batch_size': 64}\n",
    "\n",
    "model_15 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '15',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_16 = {'dropout': 0.4,\n",
    "           'recurrent_dropout': 0.4,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '16',\n",
    "           'batch_size': 32}\n",
    "\n",
    "parameters = [model_9, model_10, model_11, model_12, model_13, model_14, model_15, model_16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 9\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 200s 8ms/step - loss: 0.4233 - acc: 0.8006 - val_loss: 0.3249 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32495, saving model to saved_models/weights.9.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 198s 8ms/step - loss: 0.2635 - acc: 0.8972 - val_loss: 0.3744 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32495\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 197s 8ms/step - loss: 0.1950 - acc: 0.9261 - val_loss: 0.3196 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32495 to 0.31965, saving model to saved_models/weights.9.hdf5\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 10\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 202s 8ms/step - loss: 0.4603 - acc: 0.7743 - val_loss: 0.3239 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32389, saving model to saved_models/weights.10.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 199s 8ms/step - loss: 0.3066 - acc: 0.8750 - val_loss: 0.3065 - val_acc: 0.8769\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32389 to 0.30651, saving model to saved_models/weights.10.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 198s 8ms/step - loss: 0.2253 - acc: 0.9150 - val_loss: 0.3191 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30651\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 11\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 114s 5ms/step - loss: 0.4414 - acc: 0.7901 - val_loss: 0.2990 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29901, saving model to saved_models/weights.11.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 111s 4ms/step - loss: 0.2619 - acc: 0.8974 - val_loss: 0.2898 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29901 to 0.28983, saving model to saved_models/weights.11.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 111s 4ms/step - loss: 0.1887 - acc: 0.9307 - val_loss: 0.3261 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28983\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 12\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 114s 5ms/step - loss: 0.4728 - acc: 0.7678 - val_loss: 0.3227 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32268, saving model to saved_models/weights.12.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.3248 - acc: 0.8701 - val_loss: 0.4047 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32268\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 111s 4ms/step - loss: 0.2483 - acc: 0.9044 - val_loss: 0.3272 - val_acc: 0.8692\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32268\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 13\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 116s 5ms/step - loss: 0.4470 - acc: 0.7927 - val_loss: 0.3735 - val_acc: 0.8390\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37347, saving model to saved_models/weights.13.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.2623 - acc: 0.8978 - val_loss: 0.3019 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37347 to 0.30190, saving model to saved_models/weights.13.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 112s 4ms/step - loss: 0.1824 - acc: 0.9333 - val_loss: 0.3241 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30190\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 14\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 115s 5ms/step - loss: 0.4668 - acc: 0.7738 - val_loss: 0.3308 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33081, saving model to saved_models/weights.14.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 113s 5ms/step - loss: 0.2784 - acc: 0.8885 - val_loss: 0.3281 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33081 to 0.32810, saving model to saved_models/weights.14.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 113s 5ms/step - loss: 0.2028 - acc: 0.9239 - val_loss: 0.3130 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32810 to 0.31300, saving model to saved_models/weights.14.hdf5\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 15\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 206s 8ms/step - loss: 0.4218 - acc: 0.8053 - val_loss: 0.2990 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29899, saving model to saved_models/weights.15.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 202s 8ms/step - loss: 0.2317 - acc: 0.9112 - val_loss: 0.2883 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29899 to 0.28825, saving model to saved_models/weights.15.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 201s 8ms/step - loss: 0.1611 - acc: 0.9412 - val_loss: 0.3196 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28825\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 16\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 204s 8ms/step - loss: 0.4423 - acc: 0.7885 - val_loss: 0.3290 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32902, saving model to saved_models/weights.16.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 201s 8ms/step - loss: 0.2608 - acc: 0.8952 - val_loss: 0.2993 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32902 to 0.29933, saving model to saved_models/weights.16.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 200s 8ms/step - loss: 0.1912 - acc: 0.9258 - val_loss: 0.3141 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.29933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "# Warning: Running this code will re-train the models and overwrite the saved models.\n",
    "\n",
    "for params in parameters:\n",
    "    train_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 9\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating model 10\n",
      "12500/12500 [==============================] - 17s 1ms/step\n",
      "Evaluating model 11\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating model 12\n",
      "12500/12500 [==============================] - 17s 1ms/step\n",
      "Evaluating model 13\n",
      "12500/12500 [==============================] - 17s 1ms/step\n",
      "Evaluating model 14\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating model 15\n",
      "12500/12500 [==============================] - 17s 1ms/step\n",
      "Evaluating model 16\n",
      "12500/12500 [==============================] - 17s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>embedding</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>bidirect</th>\n",
       "      <th>model_no</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>0.87992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>0.86312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>0.86920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>0.87256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  recurrent_dropout optimizer embedding conv1d bidirect model_no  \\\n",
       "0      0.2                0.2      adam      None   True    False        9   \n",
       "1      0.4                0.4      adam      None   True    False       10   \n",
       "2      0.2                0.2      adam      None   True    False       11   \n",
       "3      0.4                0.4      adam      None   True    False       12   \n",
       "4      0.2                0.2     nadam      None   True    False       13   \n",
       "5      0.4                0.4     nadam      None   True    False       14   \n",
       "6      0.2                0.2     nadam      None   True    False       15   \n",
       "7      0.4                0.4     nadam      None   True    False       16   \n",
       "\n",
       "  batch_size  val_acc  \n",
       "0         32  0.87368  \n",
       "1         32  0.87736  \n",
       "2         64  0.87992  \n",
       "3         64  0.86312  \n",
       "4         64  0.86920  \n",
       "5         64  0.87256  \n",
       "6         32  0.88200  \n",
       "7         32  0.87584  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation summary\n",
    "\n",
    "best_params, best_accuracy, df = best_model(parameters)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dropout of 0.1 is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_17 = {'dropout': 0.1,\n",
    "           'recurrent_dropout': 0.1,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '17',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_18 = {'dropout': 0.1,\n",
    "           'recurrent_dropout': 0.1,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '18',\n",
    "           'batch_size': 32}\n",
    "\n",
    "parameters = [model_17, model_18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 17\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 385s 15ms/step - loss: 0.5159 - acc: 0.7460 - val_loss: 0.4368 - val_acc: 0.8048\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43676, saving model to saved_models/weights.17.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 381s 15ms/step - loss: 0.3144 - acc: 0.8702 - val_loss: 0.3208 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43676 to 0.32079, saving model to saved_models/weights.17.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 382s 15ms/step - loss: 0.2028 - acc: 0.9224 - val_loss: 0.2994 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32079 to 0.29937, saving model to saved_models/weights.17.hdf5\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 500, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 18\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 209s 8ms/step - loss: 0.4121 - acc: 0.8126 - val_loss: 0.3347 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33475, saving model to saved_models/weights.18.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 206s 8ms/step - loss: 0.2261 - acc: 0.9139 - val_loss: 0.3133 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33475 to 0.31330, saving model to saved_models/weights.18.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 205s 8ms/step - loss: 0.1535 - acc: 0.9460 - val_loss: 0.3145 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "# Warning: Running this code will re-train the models and overwrite the saved models.\n",
    "\n",
    "for params in parameters:\n",
    "    train_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 17\n",
      "12500/12500 [==============================] - 31s 2ms/step\n",
      "Evaluating model 18\n",
      "12500/12500 [==============================] - 17s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>embedding</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>bidirect</th>\n",
       "      <th>model_no</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>0.86912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  recurrent_dropout optimizer embedding conv1d bidirect model_no  \\\n",
       "0      0.1                0.1     nadam      None  False    False       17   \n",
       "1      0.1                0.1     nadam      None   True    False       18   \n",
       "\n",
       "  batch_size  val_acc  \n",
       "0         32  0.87472  \n",
       "1         32  0.86912  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, best_accuracy, df = best_model([model_17, model_18])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nope. Stick with 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_19 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': None,\n",
    "           'conv1d': False,\n",
    "           'bidirect': True,\n",
    "           'model_no': '19',\n",
    "           'batch_size': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, 500, 100)          1200400   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,361,401\n",
      "Trainable params: 1,361,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 19\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 469s 19ms/step - loss: 0.5196 - acc: 0.7454 - val_loss: 0.4007 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40073, saving model to saved_models/weights.19.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 466s 19ms/step - loss: 0.3627 - acc: 0.8474 - val_loss: 0.3775 - val_acc: 0.8386\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40073 to 0.37754, saving model to saved_models/weights.19.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 464s 19ms/step - loss: 0.2263 - acc: 0.9124 - val_loss: 0.2893 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37754 to 0.28928, saving model to saved_models/weights.19.hdf5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "# Warning: Running this code will re-train the models and overwrite the saved model.\n",
    "\n",
    "train_model(model_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 19\n",
      "12500/12500 [==============================] - 38s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>embedding</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>bidirect</th>\n",
       "      <th>model_no</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  recurrent_dropout optimizer embedding conv1d bidirect model_no  \\\n",
       "0      0.2                0.2     nadam      None  False     True       19   \n",
       "\n",
       "  batch_size  val_acc  \n",
       "0         32     0.88  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, best_accuracy, df = best_model([model_19])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Pre-trained embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedding layer (50): (12004, 50)\n",
      "Shape of embedding layer (100): (12004, 100)\n",
      "Shape of embedding layer (200): (12004, 200)\n",
      "Shape of embedding layer (300): (12004, 300)\n"
     ]
    }
   ],
   "source": [
    "# Generate the embedding layers\n",
    "\n",
    "embedding_50 = glove_embeddings('glove.6B.50d.txt')\n",
    "embedding_100 = glove_embeddings('glove.6B.100d.txt')\n",
    "embedding_200 = glove_embeddings('glove.6B.200d.txt')\n",
    "embedding_300 = glove_embeddings('glove.6B.300d.txt')\n",
    "\n",
    "embedding_layer_50, emb_matrix_50 = pretrained_embedding_layer(embedding_50, word2id, 50)\n",
    "embedding_layer_100, emb_matrix_100 = pretrained_embedding_layer(embedding_100, word2id, 100)\n",
    "embedding_layer_200, emb_matrix_200 = pretrained_embedding_layer(embedding_200, word2id, 200)\n",
    "embedding_layer_300, emb_matrix_300 = pretrained_embedding_layer(embedding_300, word2id, 300)\n",
    "\n",
    "print('Shape of embedding layer (50):', emb_matrix_50.shape)\n",
    "print('Shape of embedding layer (100):', emb_matrix_100.shape)\n",
    "print('Shape of embedding layer (200):', emb_matrix_200.shape)\n",
    "print('Shape of embedding layer (300):', emb_matrix_300.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_20 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': embedding_layer_50,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '20',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_21 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': embedding_layer_50,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '21',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_22 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': embedding_layer_100,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '22',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_23 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': embedding_layer_100,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '23',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_24 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': embedding_layer_200,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '24',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_25 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': embedding_layer_200,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '25',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_26 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': embedding_layer_300,\n",
    "           'conv1d': False,\n",
    "           'bidirect': False,\n",
    "           'model_no': '26',\n",
    "           'batch_size': 32}\n",
    "\n",
    "model_27 = {'dropout': 0.2,\n",
    "           'recurrent_dropout': 0.2,\n",
    "           'optimizer': 'nadam',\n",
    "           'embedding': embedding_layer_300,\n",
    "           'conv1d': True,\n",
    "           'bidirect': False,\n",
    "           'model_no': '27',\n",
    "           'batch_size': 32}\n",
    "\n",
    "parameters = [model_20, model_21, model_22, model_23, model_24, model_25, model_26, model_27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, None, 50)          600200    \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 620,451\n",
      "Trainable params: 620,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 20\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 363s 15ms/step - loss: 0.4795 - acc: 0.7616 - val_loss: 0.3115 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31150, saving model to saved_models/weights.20.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 358s 14ms/step - loss: 0.2687 - acc: 0.8923 - val_loss: 0.2555 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31150 to 0.25550, saving model to saved_models/weights.20.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 344s 14ms/step - loss: 0.2006 - acc: 0.9240 - val_loss: 0.2693 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25550\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, None, 50)          600200    \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, None, 32)          4832      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 50)                16600     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 621,683\n",
      "Trainable params: 621,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 21\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.3199 - acc: 0.8635 - val_loss: 0.2762 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27622, saving model to saved_models/weights.21.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.1901 - acc: 0.9288 - val_loss: 0.2671 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27622 to 0.26709, saving model to saved_models/weights.21.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 190s 8ms/step - loss: 0.1423 - acc: 0.9494 - val_loss: 0.3008 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26709\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, None, 100)         1200400   \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,280,901\n",
      "Trainable params: 1,280,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 22\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 387s 15ms/step - loss: 0.4026 - acc: 0.8052 - val_loss: 0.2555 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25548, saving model to saved_models/weights.22.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 382s 15ms/step - loss: 0.2126 - acc: 0.9162 - val_loss: 0.2457 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25548 to 0.24575, saving model to saved_models/weights.22.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 384s 15ms/step - loss: 0.1439 - acc: 0.9474 - val_loss: 0.2650 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24575\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, None, 100)         1200400   \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, None, 32)          9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,263,333\n",
      "Trainable params: 1,263,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 23\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 208s 8ms/step - loss: 0.3382 - acc: 0.8536 - val_loss: 0.2781 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27811, saving model to saved_models/weights.23.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 201s 8ms/step - loss: 0.1569 - acc: 0.9410 - val_loss: 0.3543 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27811\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 200s 8ms/step - loss: 0.1087 - acc: 0.9624 - val_loss: 0.3573 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27811\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, None, 200)         2400800   \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 2,721,801\n",
      "Trainable params: 2,721,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 24\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 495s 20ms/step - loss: 0.3790 - acc: 0.8232 - val_loss: 0.2574 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25741, saving model to saved_models/weights.24.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 491s 20ms/step - loss: 0.1866 - acc: 0.9296 - val_loss: 0.2483 - val_acc: 0.9024\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25741 to 0.24834, saving model to saved_models/weights.24.hdf5\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 491s 20ms/step - loss: 0.1136 - acc: 0.9592 - val_loss: 0.2883 - val_acc: 0.8965\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24834\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, None, 200)         2400800   \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, None, 32)          19232     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (None, 200)               186400    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 2,606,633\n",
      "Trainable params: 2,606,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.3217 - acc: 0.8653 - val_loss: 0.2936 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29359, saving model to saved_models/weights.25.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 252s 10ms/step - loss: 0.1398 - acc: 0.9501 - val_loss: 0.3345 - val_acc: 0.8773\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.29359\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 253s 10ms/step - loss: 0.0858 - acc: 0.9706 - val_loss: 0.3551 - val_acc: 0.8835\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.29359\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_42 (Embedding)     (None, None, 300)         3601200   \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 4,322,701\n",
      "Trainable params: 4,322,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 26\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 843s 34ms/step - loss: 0.3673 - acc: 0.8322 - val_loss: 0.2499 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24990, saving model to saved_models/weights.26.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 838s 34ms/step - loss: 0.1787 - acc: 0.9314 - val_loss: 0.2577 - val_acc: 0.8957\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24990\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 845s 34ms/step - loss: 0.1060 - acc: 0.9616 - val_loss: 0.3506 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24990\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_42 (Embedding)     (None, None, 300)         3601200   \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, None, 32)          28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 300)               399600    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 4,029,933\n",
      "Trainable params: 4,029,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training model 27\n",
      "Train on 25000 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 352s 14ms/step - loss: 0.2911 - acc: 0.8794 - val_loss: 0.2759 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27585, saving model to saved_models/weights.27.hdf5\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 346s 14ms/step - loss: 0.1217 - acc: 0.9561 - val_loss: 0.3466 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27585\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 349s 14ms/step - loss: 0.0753 - acc: 0.9727 - val_loss: 0.4123 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "# Warning: Running this code will re-train the models and overwrite the saved models.\n",
    "\n",
    "for params in parameters:\n",
    "    train_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 20\n",
      "12500/12500 [==============================] - 27s 2ms/step\n",
      "Evaluating model 21\n",
      "12500/12500 [==============================] - 15s 1ms/step\n",
      "Evaluating model 22\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating model 23\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating model 24\n",
      "12500/12500 [==============================] - 52s 4ms/step\n",
      "Evaluating model 25\n",
      "12500/12500 [==============================] - 25s 2ms/step\n",
      "Evaluating model 26\n",
      "12500/12500 [==============================] - 115s 9ms/step\n",
      "Evaluating model 27\n",
      "12500/12500 [==============================] - 42s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>embedding</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>bidirect</th>\n",
       "      <th>model_no</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  recurrent_dropout optimizer  \\\n",
       "0      0.2                0.2     nadam   \n",
       "1      0.2                0.2     nadam   \n",
       "2      0.2                0.2     nadam   \n",
       "3      0.2                0.2     nadam   \n",
       "4      0.2                0.2     nadam   \n",
       "5      0.2                0.2     nadam   \n",
       "6      0.2                0.2     nadam   \n",
       "7      0.2                0.2     nadam   \n",
       "\n",
       "                                           embedding conv1d bidirect model_no  \\\n",
       "0  <keras.layers.embeddings.Embedding object at 0...  False    False       20   \n",
       "1  <keras.layers.embeddings.Embedding object at 0...   True    False       21   \n",
       "2  <keras.layers.embeddings.Embedding object at 0...  False    False       22   \n",
       "3  <keras.layers.embeddings.Embedding object at 0...   True    False       23   \n",
       "4  <keras.layers.embeddings.Embedding object at 0...  False    False       24   \n",
       "5  <keras.layers.embeddings.Embedding object at 0...   True    False       25   \n",
       "6  <keras.layers.embeddings.Embedding object at 0...  False    False       26   \n",
       "7  <keras.layers.embeddings.Embedding object at 0...   True    False       27   \n",
       "\n",
       "  batch_size  val_acc  \n",
       "0         32  0.89712  \n",
       "1         32  0.89056  \n",
       "2         32  0.89896  \n",
       "3         32  0.88840  \n",
       "4         32  0.89960  \n",
       "5         32  0.87896  \n",
       "6         32  0.89920  \n",
       "7         32  0.88784  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation summary\n",
    "\n",
    "best_params, best_accuracy, df = best_model(parameters)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating training set accuracy on model 1\n",
      "25000/25000 [==============================] - 68s 3ms/step\n",
      "Evaluating test set accuracy on model 1\n",
      "12500/12500 [==============================] - 32s 3ms/step\n",
      "Evaluating training set accuracy on model 2\n",
      "25000/25000 [==============================] - 67s 3ms/step\n",
      "Evaluating test set accuracy on model 2\n",
      "12500/12500 [==============================] - 33s 3ms/step\n",
      "Evaluating training set accuracy on model 3\n",
      "25000/25000 [==============================] - 68s 3ms/step\n",
      "Evaluating test set accuracy on model 3\n",
      "12500/12500 [==============================] - 32s 3ms/step\n",
      "Evaluating training set accuracy on model 4\n",
      "25000/25000 [==============================] - 67s 3ms/step\n",
      "Evaluating test set accuracy on model 4\n",
      "12500/12500 [==============================] - 31s 2ms/step\n",
      "Evaluating training set accuracy on model 5\n",
      "25000/25000 [==============================] - 70s 3ms/step\n",
      "Evaluating test set accuracy on model 5\n",
      "12500/12500 [==============================] - 33s 3ms/step\n",
      "Evaluating training set accuracy on model 6\n",
      "25000/25000 [==============================] - 74s 3ms/step\n",
      "Evaluating test set accuracy on model 6\n",
      "12500/12500 [==============================] - 34s 3ms/step\n",
      "Evaluating training set accuracy on model 7\n",
      "25000/25000 [==============================] - 65s 3ms/step\n",
      "Evaluating test set accuracy on model 7\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating training set accuracy on model 8\n",
      "25000/25000 [==============================] - 81s 3ms/step\n",
      "Evaluating test set accuracy on model 8\n",
      "12500/12500 [==============================] - 42s 3ms/step\n",
      "Evaluating training set accuracy on model 9\n",
      "25000/25000 [==============================] - 37s 1ms/step\n",
      "Evaluating test set accuracy on model 9\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating training set accuracy on model 10\n",
      "25000/25000 [==============================] - 36s 1ms/step\n",
      "Evaluating test set accuracy on model 10\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating training set accuracy on model 11\n",
      "25000/25000 [==============================] - 37s 1ms/step\n",
      "Evaluating test set accuracy on model 11\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating training set accuracy on model 12\n",
      "25000/25000 [==============================] - 45s 2ms/step\n",
      "Evaluating test set accuracy on model 12\n",
      "12500/12500 [==============================] - 18s 1ms/step\n",
      "Evaluating training set accuracy on model 13\n",
      "25000/25000 [==============================] - 38s 2ms/step\n",
      "Evaluating test set accuracy on model 13\n",
      "12500/12500 [==============================] - 17s 1ms/step\n",
      "Evaluating training set accuracy on model 14\n",
      "25000/25000 [==============================] - 37s 1ms/step\n",
      "Evaluating test set accuracy on model 14\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating training set accuracy on model 15\n",
      "25000/25000 [==============================] - 38s 2ms/step\n",
      "Evaluating test set accuracy on model 15\n",
      "12500/12500 [==============================] - 17s 1ms/step\n",
      "Evaluating training set accuracy on model 16\n",
      "25000/25000 [==============================] - 37s 1ms/step\n",
      "Evaluating test set accuracy on model 16\n",
      "12500/12500 [==============================] - 16s 1ms/step\n",
      "Evaluating training set accuracy on model 17\n",
      "25000/25000 [==============================] - 64s 3ms/step\n",
      "Evaluating test set accuracy on model 17\n",
      "12500/12500 [==============================] - 29s 2ms/step\n",
      "Evaluating training set accuracy on model 18\n",
      "25000/25000 [==============================] - 39s 2ms/step\n",
      "Evaluating test set accuracy on model 18\n",
      "12500/12500 [==============================] - 18s 1ms/step\n",
      "Evaluating training set accuracy on model 19\n",
      "25000/25000 [==============================] - 87s 3ms/step\n",
      "Evaluating test set accuracy on model 19\n",
      "12500/12500 [==============================] - 40s 3ms/step\n",
      "Evaluating training set accuracy on model 20\n",
      "25000/25000 [==============================] - 59s 2ms/step\n",
      "Evaluating test set accuracy on model 20\n",
      "12500/12500 [==============================] - 25s 2ms/step\n",
      "Evaluating training set accuracy on model 21\n",
      "25000/25000 [==============================] - 32s 1ms/step\n",
      "Evaluating test set accuracy on model 21\n",
      "12500/12500 [==============================] - 14s 1ms/step\n",
      "Evaluating training set accuracy on model 22\n",
      "25000/25000 [==============================] - 60s 2ms/step\n",
      "Evaluating test set accuracy on model 22\n",
      "12500/12500 [==============================] - 28s 2ms/step\n",
      "Evaluating training set accuracy on model 23\n",
      "25000/25000 [==============================] - 34s 1ms/step\n",
      "Evaluating test set accuracy on model 23\n",
      "12500/12500 [==============================] - 14s 1ms/step\n",
      "Evaluating training set accuracy on model 24\n",
      "25000/25000 [==============================] - 106s 4ms/step\n",
      "Evaluating test set accuracy on model 24\n",
      "12500/12500 [==============================] - 50s 4ms/step\n",
      "Evaluating training set accuracy on model 25\n",
      "25000/25000 [==============================] - 48s 2ms/step\n",
      "Evaluating test set accuracy on model 25\n",
      "12500/12500 [==============================] - 21s 2ms/step\n",
      "Evaluating training set accuracy on model 26\n",
      "25000/25000 [==============================] - 236s 9ms/step\n",
      "Evaluating test set accuracy on model 26\n",
      "12500/12500 [==============================] - 114s 9ms/step\n",
      "Evaluating training set accuracy on model 27\n",
      "25000/25000 [==============================] - 91s 4ms/step\n",
      "Evaluating test set accuracy on model 27\n",
      "12500/12500 [==============================] - 43s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>embedding</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>bidirect</th>\n",
       "      <th>model_no</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.92388</td>\n",
       "      <td>0.86528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.91652</td>\n",
       "      <td>0.84112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.91716</td>\n",
       "      <td>0.84696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.89360</td>\n",
       "      <td>0.83392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.95268</td>\n",
       "      <td>0.87976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.91764</td>\n",
       "      <td>0.84328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95912</td>\n",
       "      <td>0.88032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.93352</td>\n",
       "      <td>0.86016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.96756</td>\n",
       "      <td>0.87368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.93860</td>\n",
       "      <td>0.87736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>0.95356</td>\n",
       "      <td>0.87992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>0.90988</td>\n",
       "      <td>0.86312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>0.94528</td>\n",
       "      <td>0.86920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>0.96300</td>\n",
       "      <td>0.87256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95640</td>\n",
       "      <td>0.88200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0.94032</td>\n",
       "      <td>0.87584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95908</td>\n",
       "      <td>0.87472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>0.94352</td>\n",
       "      <td>0.86912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95624</td>\n",
       "      <td>0.88000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.93768</td>\n",
       "      <td>0.89712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95992</td>\n",
       "      <td>0.89056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95812</td>\n",
       "      <td>0.89896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>0.94904</td>\n",
       "      <td>0.88840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>0.89960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>0.94156</td>\n",
       "      <td>0.87896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>0.93976</td>\n",
       "      <td>0.89920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>0.96384</td>\n",
       "      <td>0.88784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dropout  recurrent_dropout optimizer  \\\n",
       "0       0.2                0.2      adam   \n",
       "1       0.4                0.4      adam   \n",
       "2       0.2                0.2      adam   \n",
       "3       0.4                0.4      adam   \n",
       "4       0.2                0.2     nadam   \n",
       "5       0.4                0.4     nadam   \n",
       "6       0.2                0.2     nadam   \n",
       "7       0.4                0.4     nadam   \n",
       "8       0.2                0.2      adam   \n",
       "9       0.4                0.4      adam   \n",
       "10      0.2                0.2      adam   \n",
       "11      0.4                0.4      adam   \n",
       "12      0.2                0.2     nadam   \n",
       "13      0.4                0.4     nadam   \n",
       "14      0.2                0.2     nadam   \n",
       "15      0.4                0.4     nadam   \n",
       "16      0.1                0.1     nadam   \n",
       "17      0.1                0.1     nadam   \n",
       "18      0.2                0.2     nadam   \n",
       "19      0.2                0.2     nadam   \n",
       "20      0.2                0.2     nadam   \n",
       "21      0.2                0.2     nadam   \n",
       "22      0.2                0.2     nadam   \n",
       "23      0.2                0.2     nadam   \n",
       "24      0.2                0.2     nadam   \n",
       "25      0.2                0.2     nadam   \n",
       "26      0.2                0.2     nadam   \n",
       "\n",
       "                                            embedding conv1d bidirect  \\\n",
       "0                                                None  False    False   \n",
       "1                                                None  False    False   \n",
       "2                                                None  False    False   \n",
       "3                                                None  False    False   \n",
       "4                                                None  False    False   \n",
       "5                                                None  False    False   \n",
       "6                                                None  False    False   \n",
       "7                                                None  False    False   \n",
       "8                                                None   True    False   \n",
       "9                                                None   True    False   \n",
       "10                                               None   True    False   \n",
       "11                                               None   True    False   \n",
       "12                                               None   True    False   \n",
       "13                                               None   True    False   \n",
       "14                                               None   True    False   \n",
       "15                                               None   True    False   \n",
       "16                                               None  False    False   \n",
       "17                                               None   True    False   \n",
       "18                                               None  False     True   \n",
       "19  <keras.layers.embeddings.Embedding object at 0...  False    False   \n",
       "20  <keras.layers.embeddings.Embedding object at 0...   True    False   \n",
       "21  <keras.layers.embeddings.Embedding object at 0...  False    False   \n",
       "22  <keras.layers.embeddings.Embedding object at 0...   True    False   \n",
       "23  <keras.layers.embeddings.Embedding object at 0...  False    False   \n",
       "24  <keras.layers.embeddings.Embedding object at 0...   True    False   \n",
       "25  <keras.layers.embeddings.Embedding object at 0...  False    False   \n",
       "26  <keras.layers.embeddings.Embedding object at 0...   True    False   \n",
       "\n",
       "   model_no batch_size  train_acc  test_acc  \n",
       "0         1         32    0.92388   0.86528  \n",
       "1         2         32    0.91652   0.84112  \n",
       "2         3         64    0.91716   0.84696  \n",
       "3         4         64    0.89360   0.83392  \n",
       "4         5         64    0.95268   0.87976  \n",
       "5         6         64    0.91764   0.84328  \n",
       "6         7         32    0.95912   0.88032  \n",
       "7         8         32    0.93352   0.86016  \n",
       "8         9         32    0.96756   0.87368  \n",
       "9        10         32    0.93860   0.87736  \n",
       "10       11         64    0.95356   0.87992  \n",
       "11       12         64    0.90988   0.86312  \n",
       "12       13         64    0.94528   0.86920  \n",
       "13       14         64    0.96300   0.87256  \n",
       "14       15         32    0.95640   0.88200  \n",
       "15       16         32    0.94032   0.87584  \n",
       "16       17         32    0.95908   0.87472  \n",
       "17       18         32    0.94352   0.86912  \n",
       "18       19         32    0.95624   0.88000  \n",
       "19       20         32    0.93768   0.89712  \n",
       "20       21         32    0.95992   0.89056  \n",
       "21       22         32    0.95812   0.89896  \n",
       "22       23         32    0.94904   0.88840  \n",
       "23       24         32    0.97000   0.89960  \n",
       "24       25         32    0.94156   0.87896  \n",
       "25       26         32    0.93976   0.89920  \n",
       "26       27         32    0.96384   0.88784  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, \n",
    "              model_9, model_10, model_11, model_12, model_13, model_14, model_15, model_16,\n",
    "              model_17, model_18, model_19, model_20, model_21, model_22, model_23, model_24,\n",
    "              model_25, model_26, model_27]\n",
    "\n",
    "best_params, best_accuracy, df = best_model(parameters)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confusion matrix for model 20\n",
    "\n",
    "model = build_model(dropout=0.2, recurrent_dropout=0.2, optimizer='nadam', \n",
    "                    embedding=embedding_layer_50, conv1d=False, bidirect=False, summary=False)\n",
    "model.load_weights('saved_models/weights.' + '20' + '.hdf5')\n",
    "\n",
    "predictions = (model.predict(X_test) > 0.5) * 1\n",
    "c_matrix_rnn = confusion_matrix(y_test, predictions, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[5538  712]\n",
      " [ 574 5676]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(c_matrix_rnn, ['+', '-'], title='', filename='fig5.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was exploratory and is not crucial to the project. The model weights have not been included in the \n",
    "# submission to reduce the amount of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_gru(dropout, recurrent_dropout, optimizer, embedding=None, conv1d=False, bidirect=False, summary=True):\n",
    "    \n",
    "    if embedding is None:\n",
    "        dim = 100\n",
    "    else:\n",
    "        dim = dim = embedding.get_weights()[0].shape[1]\n",
    "    \n",
    "    model = Sequential() \n",
    "    if embedding is None:\n",
    "        model.add(Embedding(input_dim=12004, output_dim=dim, input_length=max_length))\n",
    "    else:\n",
    "        model.add(embedding)\n",
    "    if conv1d:\n",
    "        model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "    if bidirect:\n",
    "        model.add(Bidirectional(GRU(dim, return_sequences=False, \n",
    "                                     dropout=dropout, recurrent_dropout=recurrent_dropout)))\n",
    "    else:\n",
    "        model.add(GRU(dim, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_gru(params):\n",
    "    \n",
    "    dropout = params['dropout']\n",
    "    recurrent_dropout = params['recurrent_dropout']\n",
    "    optimizer = params['optimizer']\n",
    "    embedding = params['embedding']\n",
    "    conv1d = params['conv1d']\n",
    "    bidirect = params['bidirect']\n",
    "    model_no = params['model_no']\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    model = build_model_gru(dropout, recurrent_dropout, optimizer, embedding, conv1d, bidirect)\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='saved_models/weights.gru.' + model_no + '.hdf5', \n",
    "                                   verbose=1, save_best_only=True)\n",
    "    \n",
    "    print('Training model', model_no)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, \n",
    "              batch_size=batch_size, callbacks=[checkpointer])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_gru(parameters):\n",
    "    \n",
    "    columns = list(parameters[0].keys())\n",
    "    columns + ['val_acc']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for params in parameters:\n",
    "        dropout = params['dropout']\n",
    "        recurrent_dropout = params['recurrent_dropout']\n",
    "        optimizer = params['optimizer']\n",
    "        embedding = params['embedding']\n",
    "        conv1d = params['conv1d']\n",
    "        bidirect = params['bidirect']\n",
    "        model_no = params['model_no']\n",
    "        batch_size = params['batch_size']\n",
    "        \n",
    "        model = build_model_gru(dropout, recurrent_dropout, optimizer, embedding, conv1d, bidirect, summary=False)\n",
    "        model.load_weights('saved_models/weights.gru.' + model_no + '.hdf5')\n",
    "        print('Evaluating model', model_no)\n",
    "        _, accuracy = model.evaluate(X_test, y_test)\n",
    "        \n",
    "        params['val_acc'] = accuracy\n",
    "        df = df.append(params, ignore_index=True)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_params = params\n",
    "            best_accuracy = accuracy\n",
    "        \n",
    "    return best_params, best_accuracy, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to be evaluated\n",
    "\n",
    "parameters = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, \n",
    "              model_9, model_10, model_11, model_12, model_13, model_14, model_15, model_16,\n",
    "              model_17, model_18, model_19, model_20, model_21, model_22, model_23, model_24,\n",
    "              model_25, model_26, model_27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "# Warning: Running this code will re-train the models and overwrite the saved models.\n",
    "\n",
    "for params in parameters:\n",
    "    train_model_gru(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 1\n",
      "12500/12500 [==============================] - 31s 2ms/step\n",
      "Evaluating model 2\n",
      "12500/12500 [==============================] - 32s 3ms/step\n",
      "Evaluating model 3\n",
      "12500/12500 [==============================] - 29s 2ms/step\n",
      "Evaluating model 4\n",
      "12500/12500 [==============================] - 28s 2ms/step\n",
      "Evaluating model 5\n",
      "12500/12500 [==============================] - 28s 2ms/step\n",
      "Evaluating model 6\n",
      "12500/12500 [==============================] - 28s 2ms/step\n",
      "Evaluating model 7\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating model 8\n",
      "12500/12500 [==============================] - 30s 2ms/step\n",
      "Evaluating model 9\n",
      "12500/12500 [==============================] - 18s 1ms/step\n",
      "Evaluating model 10\n",
      "12500/12500 [==============================] - 18s 1ms/step\n",
      "Evaluating model 11\n",
      "12500/12500 [==============================] - 18s 1ms/step\n",
      "Evaluating model 12\n",
      "12500/12500 [==============================] - 18s 1ms/step\n",
      "Evaluating model 13\n",
      "12500/12500 [==============================] - 19s 1ms/step\n",
      "Evaluating model 14\n",
      "12500/12500 [==============================] - 18s 1ms/step\n",
      "Evaluating model 15\n",
      "12500/12500 [==============================] - 18s 1ms/step\n",
      "Evaluating model 16\n",
      "12500/12500 [==============================] - 19s 2ms/step\n",
      "Evaluating model 17\n",
      "12500/12500 [==============================] - 31s 2ms/step\n",
      "Evaluating model 18\n",
      "12500/12500 [==============================] - 19s 1ms/step\n",
      "Evaluating model 19\n",
      "12500/12500 [==============================] - 38s 3ms/step\n",
      "Evaluating model 20\n",
      "12500/12500 [==============================] - 23s 2ms/step\n",
      "Evaluating model 21\n",
      "12500/12500 [==============================] - 15s 1ms/step\n",
      "Evaluating model 22\n",
      "12500/12500 [==============================] - 27s 2ms/step\n",
      "Evaluating model 23\n",
      "12500/12500 [==============================] - 17s 1ms/step\n",
      "Evaluating model 24\n",
      "12500/12500 [==============================] - 48s 4ms/step\n",
      "Evaluating model 25\n",
      "12500/12500 [==============================] - 26s 2ms/step\n",
      "Evaluating model 26\n",
      "12500/12500 [==============================] - 103s 8ms/step\n",
      "Evaluating model 27\n",
      "12500/12500 [==============================] - 42s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>embedding</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>bidirect</th>\n",
       "      <th>model_no</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.86360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.84512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.87920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.88544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.86824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>0.87344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>0.86872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>0.88232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>0.87264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.89096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>nadam</td>\n",
       "      <td>&lt;keras.layers.embeddings.Embedding object at 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>0.87048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dropout  recurrent_dropout optimizer  \\\n",
       "0       0.2                0.2      adam   \n",
       "1       0.4                0.4      adam   \n",
       "2       0.2                0.2      adam   \n",
       "3       0.4                0.4      adam   \n",
       "4       0.2                0.2     nadam   \n",
       "5       0.4                0.4     nadam   \n",
       "6       0.2                0.2     nadam   \n",
       "7       0.4                0.4     nadam   \n",
       "8       0.2                0.2      adam   \n",
       "9       0.4                0.4      adam   \n",
       "10      0.2                0.2      adam   \n",
       "11      0.4                0.4      adam   \n",
       "12      0.2                0.2     nadam   \n",
       "13      0.4                0.4     nadam   \n",
       "14      0.2                0.2     nadam   \n",
       "15      0.4                0.4     nadam   \n",
       "16      0.1                0.1     nadam   \n",
       "17      0.1                0.1     nadam   \n",
       "18      0.2                0.2     nadam   \n",
       "19      0.2                0.2     nadam   \n",
       "20      0.2                0.2     nadam   \n",
       "21      0.2                0.2     nadam   \n",
       "22      0.2                0.2     nadam   \n",
       "23      0.2                0.2     nadam   \n",
       "24      0.2                0.2     nadam   \n",
       "25      0.2                0.2     nadam   \n",
       "26      0.2                0.2     nadam   \n",
       "\n",
       "                                            embedding conv1d bidirect  \\\n",
       "0                                                None  False    False   \n",
       "1                                                None  False    False   \n",
       "2                                                None  False    False   \n",
       "3                                                None  False    False   \n",
       "4                                                None  False    False   \n",
       "5                                                None  False    False   \n",
       "6                                                None  False    False   \n",
       "7                                                None  False    False   \n",
       "8                                                None   True    False   \n",
       "9                                                None   True    False   \n",
       "10                                               None   True    False   \n",
       "11                                               None   True    False   \n",
       "12                                               None   True    False   \n",
       "13                                               None   True    False   \n",
       "14                                               None   True    False   \n",
       "15                                               None   True    False   \n",
       "16                                               None  False    False   \n",
       "17                                               None   True    False   \n",
       "18                                               None  False     True   \n",
       "19  <keras.layers.embeddings.Embedding object at 0...  False    False   \n",
       "20  <keras.layers.embeddings.Embedding object at 0...   True    False   \n",
       "21  <keras.layers.embeddings.Embedding object at 0...  False    False   \n",
       "22  <keras.layers.embeddings.Embedding object at 0...   True    False   \n",
       "23  <keras.layers.embeddings.Embedding object at 0...  False    False   \n",
       "24  <keras.layers.embeddings.Embedding object at 0...   True    False   \n",
       "25  <keras.layers.embeddings.Embedding object at 0...  False    False   \n",
       "26  <keras.layers.embeddings.Embedding object at 0...   True    False   \n",
       "\n",
       "   model_no batch_size  val_acc  \n",
       "0         1         32  0.87928  \n",
       "1         2         32  0.88200  \n",
       "2         3         64  0.86360  \n",
       "3         4         64  0.84512  \n",
       "4         5         64  0.87920  \n",
       "5         6         64  0.88544  \n",
       "6         7         32  0.88704  \n",
       "7         8         32  0.89176  \n",
       "8         9         32  0.88144  \n",
       "9        10         32  0.86824  \n",
       "10       11         64  0.87344  \n",
       "11       12         64  0.86872  \n",
       "12       13         64  0.88232  \n",
       "13       14         64  0.87264  \n",
       "14       15         32  0.88504  \n",
       "15       16         32  0.88672  \n",
       "16       17         32  0.89744  \n",
       "17       18         32  0.89120  \n",
       "18       19         32  0.88584  \n",
       "19       20         32  0.89096  \n",
       "20       21         32  0.88920  \n",
       "21       22         32  0.88704  \n",
       "22       23         32  0.88032  \n",
       "23       24         32  0.88920  \n",
       "24       25         32  0.87904  \n",
       "25       26         32  0.87184  \n",
       "26       27         32  0.87048  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation summary\n",
    "\n",
    "best_params, best_accuracy, df = best_model_gru(parameters)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 552.96x414.72 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpltools import layout\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "figsize = layout.figaspect(scale=1.2)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=figsize)\n",
    "x = np.arange(0, 4, 1)\n",
    "acc = [0.819, 0.838, 0.882, 0.897]\n",
    "ax1.scatter(x, acc, c='dodgerblue', s=80, edgecolors='k')\n",
    "ax1.set_xlabel('Model', fontsize=20, labelpad=15)\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "ax1.set_ylabel('Accuracy', color='dodgerblue', fontsize=20, labelpad=15)\n",
    "ax1.tick_params('y', colors='dodgerblue', labelsize=18)\n",
    "ax1.tick_params('x', labelsize=18)\n",
    "ax1.set_xticklabels(labels=['', 'NB', 'BNB', 'SVM', 'RNN'], fontdict={'fontsize':16})\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "time = [0.031, 0.058, 0.968, 1062] \n",
    "ax2.scatter(x, time, c='firebrick', s=80, edgecolors='k')\n",
    "ax2.set_ylabel('Training time (s)', color='firebrick', fontsize=20, rotation=270, labelpad=22)\n",
    "ax2.set_yscale('log')\n",
    "ax2.tick_params('y', colors='firebrick', labelsize=18)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('fig6.eps', dpi=300, format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
